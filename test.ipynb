{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 01 Diabetic Related Complications and Risk Level\n",
    "\n",
    "## 1.1 Diabetic Related Complications\n",
    "\n",
    "### inputs\n",
    "\n",
    "patient_code\tfemale_gender\tage_years\teducation_level\teducation_standard\teducation_advanced\tbmi_kgm2\tdiabetes_type\tdmt1\tdiabetes_duration\tinsulin_treatment\tonly_med_treatment\thba1c_percent\thba1c_mmol\n",
    "\n",
    "### Outputs\n",
    "\n",
    "Probabilities (Out of 100%)\n",
    "\n",
    "nephropathy\tretinopathy\tneuropathy\tfoot_ulcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset=pd.read_csv('diabetic_complication.csv').values\n",
    "data=dataset[:,0:7]\n",
    "target_1=dataset[:,7]\n",
    "target_2=dataset[:,8]\n",
    "target_3=dataset[:,9]\n",
    "target_4=dataset[:,10]\n",
    "\n",
    "np.save('data_diabetic_complications',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(data)\n",
    "xscale=scaler_x.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "\n",
    "    import keras.models as models\n",
    "    import keras.layers as layers\n",
    "    import keras.optimizers as optimizers\n",
    "    from keras.layers import Dropout\n",
    "    import numpy as np\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot(name):\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.savefig('data/graphs/'+name+'_loss.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model acc')\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.savefig('data/graphs/'+name+'_acc.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nephropathy retinopathy neuropathy foot_ulcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.6836 - accuracy: 0.6149 - val_loss: 0.6418 - val_accuracy: 0.9487\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.6125 - accuracy: 0.8879 - val_loss: 0.5441 - val_accuracy: 0.9487\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.5148 - accuracy: 0.8879 - val_loss: 0.3895 - val_accuracy: 0.9487\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4081 - accuracy: 0.8879 - val_loss: 0.2558 - val_accuracy: 0.9487\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3792 - accuracy: 0.8879 - val_loss: 0.2236 - val_accuracy: 0.9487\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3751 - accuracy: 0.8879 - val_loss: 0.2320 - val_accuracy: 0.9487\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3717 - accuracy: 0.8879 - val_loss: 0.2383 - val_accuracy: 0.9487\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3764 - accuracy: 0.8879 - val_loss: 0.2417 - val_accuracy: 0.9487\n",
      "Epoch 9/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3650 - accuracy: 0.8879 - val_loss: 0.2352 - val_accuracy: 0.9487\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3683 - accuracy: 0.8879 - val_loss: 0.2307 - val_accuracy: 0.9487\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3654 - accuracy: 0.8879 - val_loss: 0.2358 - val_accuracy: 0.9487\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3717 - accuracy: 0.8879 - val_loss: 0.2329 - val_accuracy: 0.9487\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3628 - accuracy: 0.8879 - val_loss: 0.2259 - val_accuracy: 0.9487\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3650 - accuracy: 0.8879 - val_loss: 0.2331 - val_accuracy: 0.9487\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3679 - accuracy: 0.8879 - val_loss: 0.2312 - val_accuracy: 0.9487\n",
      "Epoch 16/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3746 - accuracy: 0.8879 - val_loss: 0.2317 - val_accuracy: 0.9487\n",
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3517 - accuracy: 0.8879 - val_loss: 0.2367 - val_accuracy: 0.9487\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3424 - accuracy: 0.8879 - val_loss: 0.2202 - val_accuracy: 0.9487\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3609 - accuracy: 0.8879 - val_loss: 0.2277 - val_accuracy: 0.9487\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 135us/step - loss: 0.3530 - accuracy: 0.8879 - val_loss: 0.2234 - val_accuracy: 0.9487\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 201us/step - loss: 0.3498 - accuracy: 0.8879 - val_loss: 0.2225 - val_accuracy: 0.9487\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 132us/step - loss: 0.3492 - accuracy: 0.8879 - val_loss: 0.2274 - val_accuracy: 0.9487\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 152us/step - loss: 0.3442 - accuracy: 0.8879 - val_loss: 0.2228 - val_accuracy: 0.9487\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.3500 - accuracy: 0.8879 - val_loss: 0.2242 - val_accuracy: 0.9487\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.3388 - accuracy: 0.8879 - val_loss: 0.2236 - val_accuracy: 0.9487\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 161us/step - loss: 0.3316 - accuracy: 0.8879 - val_loss: 0.2154 - val_accuracy: 0.9487\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 141us/step - loss: 0.3475 - accuracy: 0.8879 - val_loss: 0.2236 - val_accuracy: 0.9487\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 161us/step - loss: 0.3284 - accuracy: 0.8879 - val_loss: 0.2180 - val_accuracy: 0.9487\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 150us/step - loss: 0.3423 - accuracy: 0.8879 - val_loss: 0.2192 - val_accuracy: 0.9487\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 144us/step - loss: 0.3287 - accuracy: 0.8879 - val_loss: 0.2160 - val_accuracy: 0.9487\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 138us/step - loss: 0.3364 - accuracy: 0.8879 - val_loss: 0.2227 - val_accuracy: 0.9487\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 129us/step - loss: 0.3354 - accuracy: 0.8879 - val_loss: 0.2106 - val_accuracy: 0.9487\n",
      "Epoch 33/200\n",
      "348/348 [==============================] - 0s 138us/step - loss: 0.3304 - accuracy: 0.8879 - val_loss: 0.2167 - val_accuracy: 0.9487\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - 0s 132us/step - loss: 0.3287 - accuracy: 0.8879 - val_loss: 0.2223 - val_accuracy: 0.9487\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - 0s 152us/step - loss: 0.3302 - accuracy: 0.8879 - val_loss: 0.2179 - val_accuracy: 0.9487\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 135us/step - loss: 0.3219 - accuracy: 0.8879 - val_loss: 0.2205 - val_accuracy: 0.9487\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 138us/step - loss: 0.3261 - accuracy: 0.8879 - val_loss: 0.2138 - val_accuracy: 0.9487\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3234 - accuracy: 0.8879 - val_loss: 0.2110 - val_accuracy: 0.9487\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3245 - accuracy: 0.8879 - val_loss: 0.2312 - val_accuracy: 0.9487\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - 0s 138us/step - loss: 0.3191 - accuracy: 0.8879 - val_loss: 0.2145 - val_accuracy: 0.9487\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.90 - 0s 112us/step - loss: 0.3225 - accuracy: 0.8879 - val_loss: 0.2135 - val_accuracy: 0.9487\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3205 - accuracy: 0.8879 - val_loss: 0.2155 - val_accuracy: 0.9487\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 102us/step - loss: 0.3222 - accuracy: 0.8879 - val_loss: 0.2295 - val_accuracy: 0.9487\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 88us/step - loss: 0.3118 - accuracy: 0.8879 - val_loss: 0.2216 - val_accuracy: 0.9487\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3157 - accuracy: 0.8879 - val_loss: 0.2105 - val_accuracy: 0.9487\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3082 - accuracy: 0.8879 - val_loss: 0.2185 - val_accuracy: 0.9487\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3139 - accuracy: 0.8879 - val_loss: 0.2326 - val_accuracy: 0.9487\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3162 - accuracy: 0.8879 - val_loss: 0.2239 - val_accuracy: 0.9487\n",
      "Epoch 49/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.3289 - accuracy: 0.8879 - val_loss: 0.2250 - val_accuracy: 0.9487\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3115 - accuracy: 0.8879 - val_loss: 0.2160 - val_accuracy: 0.9487\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3012 - accuracy: 0.8879 - val_loss: 0.2158 - val_accuracy: 0.9487\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 135us/step - loss: 0.3042 - accuracy: 0.8879 - val_loss: 0.2298 - val_accuracy: 0.9487\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3115 - accuracy: 0.8879 - val_loss: 0.2266 - val_accuracy: 0.9487\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3113 - accuracy: 0.8879 - val_loss: 0.2274 - val_accuracy: 0.9487\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3162 - accuracy: 0.8879 - val_loss: 0.2401 - val_accuracy: 0.9487\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 92us/step - loss: 0.3086 - accuracy: 0.8879 - val_loss: 0.2219 - val_accuracy: 0.9487\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2998 - accuracy: 0.8879 - val_loss: 0.2242 - val_accuracy: 0.9487\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3072 - accuracy: 0.8879 - val_loss: 0.2378 - val_accuracy: 0.9487\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2978 - accuracy: 0.8879 - val_loss: 0.2272 - val_accuracy: 0.9487\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3005 - accuracy: 0.8879 - val_loss: 0.2316 - val_accuracy: 0.9487\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3163 - accuracy: 0.8879 - val_loss: 0.2404 - val_accuracy: 0.9487\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3042 - accuracy: 0.8879 - val_loss: 0.2286 - val_accuracy: 0.9487\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3061 - accuracy: 0.8879 - val_loss: 0.2378 - val_accuracy: 0.9487\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3012 - accuracy: 0.8879 - val_loss: 0.2317 - val_accuracy: 0.9487\n",
      "Epoch 65/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3122 - accuracy: 0.8879 - val_loss: 0.2457 - val_accuracy: 0.9487\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3034 - accuracy: 0.8879 - val_loss: 0.2343 - val_accuracy: 0.9487\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2993 - accuracy: 0.8879 - val_loss: 0.2300 - val_accuracy: 0.9487\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2959 - accuracy: 0.8879 - val_loss: 0.2335 - val_accuracy: 0.9487\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3042 - accuracy: 0.8879 - val_loss: 0.2258 - val_accuracy: 0.9487\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3094 - accuracy: 0.8879 - val_loss: 0.2499 - val_accuracy: 0.9487\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2949 - accuracy: 0.8879 - val_loss: 0.2251 - val_accuracy: 0.9487\n",
      "Epoch 72/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2956 - accuracy: 0.8879 - val_loss: 0.2265 - val_accuracy: 0.9487\n",
      "Epoch 73/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3043 - accuracy: 0.8879 - val_loss: 0.2319 - val_accuracy: 0.9487\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3077 - accuracy: 0.8879 - val_loss: 0.2401 - val_accuracy: 0.9487\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.2931 - accuracy: 0.8879 - val_loss: 0.2364 - val_accuracy: 0.9487\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2985 - accuracy: 0.8879 - val_loss: 0.2327 - val_accuracy: 0.9487\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3104 - accuracy: 0.8879 - val_loss: 0.2505 - val_accuracy: 0.9487\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2929 - accuracy: 0.8879 - val_loss: 0.2346 - val_accuracy: 0.9487\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2955 - accuracy: 0.8879 - val_loss: 0.2303 - val_accuracy: 0.9487\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3015 - accuracy: 0.8879 - val_loss: 0.2331 - val_accuracy: 0.9487\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2966 - accuracy: 0.8879 - val_loss: 0.2442 - val_accuracy: 0.9487\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2988 - accuracy: 0.8879 - val_loss: 0.2338 - val_accuracy: 0.9487\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3017 - accuracy: 0.8879 - val_loss: 0.2436 - val_accuracy: 0.9487\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3005 - accuracy: 0.8879 - val_loss: 0.2342 - val_accuracy: 0.9487\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3005 - accuracy: 0.8879 - val_loss: 0.2355 - val_accuracy: 0.9487\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2950 - accuracy: 0.8879 - val_loss: 0.2499 - val_accuracy: 0.9487\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2939 - accuracy: 0.8879 - val_loss: 0.2343 - val_accuracy: 0.9487\n",
      "Epoch 88/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2939 - accuracy: 0.8879 - val_loss: 0.2436 - val_accuracy: 0.9487\n",
      "Epoch 89/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.2920 - accuracy: 0.8879 - val_loss: 0.2449 - val_accuracy: 0.9487\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2883 - accuracy: 0.8879 - val_loss: 0.2329 - val_accuracy: 0.9487\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2859 - accuracy: 0.8879 - val_loss: 0.2397 - val_accuracy: 0.9487\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2984 - accuracy: 0.8879 - val_loss: 0.2371 - val_accuracy: 0.9487\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2975 - accuracy: 0.8879 - val_loss: 0.2458 - val_accuracy: 0.9487\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2860 - accuracy: 0.8879 - val_loss: 0.2414 - val_accuracy: 0.9487\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2931 - accuracy: 0.8879 - val_loss: 0.2404 - val_accuracy: 0.9487\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2877 - accuracy: 0.8879 - val_loss: 0.2302 - val_accuracy: 0.9487\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2901 - accuracy: 0.8879 - val_loss: 0.2364 - val_accuracy: 0.9487\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2941 - accuracy: 0.8879 - val_loss: 0.2521 - val_accuracy: 0.9487\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2963 - accuracy: 0.8879 - val_loss: 0.2379 - val_accuracy: 0.9487\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2931 - accuracy: 0.8879 - val_loss: 0.2409 - val_accuracy: 0.9487\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2959 - accuracy: 0.8879 - val_loss: 0.2415 - val_accuracy: 0.9487\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2972 - accuracy: 0.8879 - val_loss: 0.2366 - val_accuracy: 0.9487\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2907 - accuracy: 0.8879 - val_loss: 0.2343 - val_accuracy: 0.9487\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2845 - accuracy: 0.8879 - val_loss: 0.2320 - val_accuracy: 0.9487\n",
      "Epoch 105/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2880 - accuracy: 0.8879 - val_loss: 0.2466 - val_accuracy: 0.9487\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2763 - accuracy: 0.8879 - val_loss: 0.2432 - val_accuracy: 0.9487\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2995 - accuracy: 0.8879 - val_loss: 0.2357 - val_accuracy: 0.9487\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2757 - accuracy: 0.8879 - val_loss: 0.2494 - val_accuracy: 0.9487\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2870 - accuracy: 0.8879 - val_loss: 0.2490 - val_accuracy: 0.9487\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.2900 - accuracy: 0.8879 - val_loss: 0.2464 - val_accuracy: 0.9487\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2984 - accuracy: 0.8879 - val_loss: 0.2400 - val_accuracy: 0.9487\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 95us/step - loss: 0.2852 - accuracy: 0.8879 - val_loss: 0.2348 - val_accuracy: 0.9487\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2821 - accuracy: 0.8879 - val_loss: 0.2411 - val_accuracy: 0.9487\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2847 - accuracy: 0.8879 - val_loss: 0.2525 - val_accuracy: 0.9487\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2849 - accuracy: 0.8879 - val_loss: 0.2422 - val_accuracy: 0.9487\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2928 - accuracy: 0.8879 - val_loss: 0.2374 - val_accuracy: 0.9487\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2949 - accuracy: 0.8879 - val_loss: 0.2538 - val_accuracy: 0.9487\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2876 - accuracy: 0.8879 - val_loss: 0.2401 - val_accuracy: 0.9487\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2888 - accuracy: 0.8879 - val_loss: 0.2377 - val_accuracy: 0.9487\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2810 - accuracy: 0.8879 - val_loss: 0.2385 - val_accuracy: 0.9487\n",
      "Epoch 121/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2844 - accuracy: 0.8879 - val_loss: 0.2433 - val_accuracy: 0.9487\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2914 - accuracy: 0.8879 - val_loss: 0.2558 - val_accuracy: 0.9487\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.2857 - accuracy: 0.8879 - val_loss: 0.2417 - val_accuracy: 0.9487\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2865 - accuracy: 0.8879 - val_loss: 0.2525 - val_accuracy: 0.9487\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2920 - accuracy: 0.8879 - val_loss: 0.2393 - val_accuracy: 0.9487\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2854 - accuracy: 0.8879 - val_loss: 0.2354 - val_accuracy: 0.9487\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3054 - accuracy: 0.8879 - val_loss: 0.2483 - val_accuracy: 0.9487\n",
      "Epoch 128/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2955 - accuracy: 0.8879 - val_loss: 0.2475 - val_accuracy: 0.9487\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2829 - accuracy: 0.8879 - val_loss: 0.2459 - val_accuracy: 0.9487\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2939 - accuracy: 0.8879 - val_loss: 0.2481 - val_accuracy: 0.9487\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2964 - accuracy: 0.8879 - val_loss: 0.2456 - val_accuracy: 0.9487\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2963 - accuracy: 0.8879 - val_loss: 0.2398 - val_accuracy: 0.9487\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2787 - accuracy: 0.8879 - val_loss: 0.2419 - val_accuracy: 0.9487\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2973 - accuracy: 0.8879 - val_loss: 0.2378 - val_accuracy: 0.9487\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2818 - accuracy: 0.8908 - val_loss: 0.2551 - val_accuracy: 0.9487\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2982 - accuracy: 0.8879 - val_loss: 0.2375 - val_accuracy: 0.9487\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2765 - accuracy: 0.8879 - val_loss: 0.2446 - val_accuracy: 0.9487\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2846 - accuracy: 0.8879 - val_loss: 0.2429 - val_accuracy: 0.9487\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2814 - accuracy: 0.8879 - val_loss: 0.2543 - val_accuracy: 0.9487\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2908 - accuracy: 0.8879 - val_loss: 0.2456 - val_accuracy: 0.9487\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2952 - accuracy: 0.8879 - val_loss: 0.2489 - val_accuracy: 0.9487\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2854 - accuracy: 0.8879 - val_loss: 0.2439 - val_accuracy: 0.9487\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.2945 - accuracy: 0.8879 - val_loss: 0.2406 - val_accuracy: 0.9487\n",
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2843 - accuracy: 0.8879 - val_loss: 0.2476 - val_accuracy: 0.9487\n",
      "Epoch 145/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2781 - accuracy: 0.8879 - val_loss: 0.2388 - val_accuracy: 0.9487\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2918 - accuracy: 0.8879 - val_loss: 0.2414 - val_accuracy: 0.9487\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.2793 - accuracy: 0.8879 - val_loss: 0.2407 - val_accuracy: 0.9487\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 138us/step - loss: 0.2830 - accuracy: 0.8879 - val_loss: 0.2520 - val_accuracy: 0.9487\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2823 - accuracy: 0.8908 - val_loss: 0.2532 - val_accuracy: 0.9487\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.2855 - accuracy: 0.8879 - val_loss: 0.2377 - val_accuracy: 0.9487\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 132us/step - loss: 0.2838 - accuracy: 0.8879 - val_loss: 0.2569 - val_accuracy: 0.9487\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.2733 - accuracy: 0.8879 - val_loss: 0.2527 - val_accuracy: 0.9487\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2846 - accuracy: 0.8879 - val_loss: 0.2445 - val_accuracy: 0.9487\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.2744 - accuracy: 0.8879 - val_loss: 0.2496 - val_accuracy: 0.9487\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2652 - accuracy: 0.8879 - val_loss: 0.2448 - val_accuracy: 0.9487\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2820 - accuracy: 0.8879 - val_loss: 0.2387 - val_accuracy: 0.9487\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2968 - accuracy: 0.8879 - val_loss: 0.2506 - val_accuracy: 0.9487\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2852 - accuracy: 0.8879 - val_loss: 0.2548 - val_accuracy: 0.9487\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2809 - accuracy: 0.8879 - val_loss: 0.2458 - val_accuracy: 0.9487\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2898 - accuracy: 0.8879 - val_loss: 0.2407 - val_accuracy: 0.9487\n",
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2894 - accuracy: 0.8879 - val_loss: 0.2522 - val_accuracy: 0.9487\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2832 - accuracy: 0.8879 - val_loss: 0.2489 - val_accuracy: 0.9487\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2873 - accuracy: 0.8908 - val_loss: 0.2438 - val_accuracy: 0.9487\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2741 - accuracy: 0.8879 - val_loss: 0.2416 - val_accuracy: 0.9487\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2771 - accuracy: 0.8879 - val_loss: 0.2389 - val_accuracy: 0.9487\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2830 - accuracy: 0.8908 - val_loss: 0.2447 - val_accuracy: 0.9487\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2948 - accuracy: 0.8879 - val_loss: 0.2462 - val_accuracy: 0.9487\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 106us/step - loss: 0.2737 - accuracy: 0.8879 - val_loss: 0.2479 - val_accuracy: 0.9487\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2951 - accuracy: 0.8879 - val_loss: 0.2468 - val_accuracy: 0.9487\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2715 - accuracy: 0.8879 - val_loss: 0.2486 - val_accuracy: 0.9487\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2926 - accuracy: 0.8908 - val_loss: 0.2530 - val_accuracy: 0.9487\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2780 - accuracy: 0.8879 - val_loss: 0.2380 - val_accuracy: 0.9487\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2888 - accuracy: 0.8879 - val_loss: 0.2404 - val_accuracy: 0.9487\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2923 - accuracy: 0.8879 - val_loss: 0.2667 - val_accuracy: 0.9487\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2816 - accuracy: 0.8879 - val_loss: 0.2476 - val_accuracy: 0.9487\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 81us/step - loss: 0.3056 - accuracy: 0.8879 - val_loss: 0.2459 - val_accuracy: 0.9487\n",
      "Epoch 177/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.2801 - accuracy: 0.8908 - val_loss: 0.2543 - val_accuracy: 0.9487\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2797 - accuracy: 0.8879 - val_loss: 0.2528 - val_accuracy: 0.9487\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - 0s 91us/step - loss: 0.2643 - accuracy: 0.8879 - val_loss: 0.2425 - val_accuracy: 0.9487\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 93us/step - loss: 0.2753 - accuracy: 0.8879 - val_loss: 0.2524 - val_accuracy: 0.9487\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.2840 - accuracy: 0.8879 - val_loss: 0.2488 - val_accuracy: 0.9487\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.2687 - accuracy: 0.8879 - val_loss: 0.2519 - val_accuracy: 0.9487\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2823 - accuracy: 0.8879 - val_loss: 0.2619 - val_accuracy: 0.9487\n",
      "Epoch 184/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2700 - accuracy: 0.8879 - val_loss: 0.2591 - val_accuracy: 0.9487\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 81us/step - loss: 0.2674 - accuracy: 0.8879 - val_loss: 0.2577 - val_accuracy: 0.9487\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2687 - accuracy: 0.8908 - val_loss: 0.2560 - val_accuracy: 0.9487\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.2755 - accuracy: 0.8879 - val_loss: 0.2679 - val_accuracy: 0.9487\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2823 - accuracy: 0.8879 - val_loss: 0.2653 - val_accuracy: 0.9487\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2728 - accuracy: 0.8879 - val_loss: 0.2618 - val_accuracy: 0.9487\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2761 - accuracy: 0.8879 - val_loss: 0.2643 - val_accuracy: 0.9487\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2779 - accuracy: 0.8879 - val_loss: 0.2599 - val_accuracy: 0.9487\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2842 - accuracy: 0.8879 - val_loss: 0.2668 - val_accuracy: 0.9487\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2778 - accuracy: 0.8908 - val_loss: 0.2736 - val_accuracy: 0.9487\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2667 - accuracy: 0.8908 - val_loss: 0.2616 - val_accuracy: 0.9487\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2785 - accuracy: 0.8879 - val_loss: 0.2555 - val_accuracy: 0.9487\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2854 - accuracy: 0.8879 - val_loss: 0.2676 - val_accuracy: 0.9487\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2671 - accuracy: 0.8908 - val_loss: 0.2487 - val_accuracy: 0.9487\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2783 - accuracy: 0.8879 - val_loss: 0.2404 - val_accuracy: 0.9487\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2712 - accuracy: 0.8879 - val_loss: 0.2436 - val_accuracy: 0.9487\n",
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2860 - accuracy: 0.8879 - val_loss: 0.2563 - val_accuracy: 0.9487\n",
      "Predicted: [[7.38856196e-03]\n",
      " [1.44775003e-01]\n",
      " [3.21778655e-02]\n",
      " [8.70478153e-03]\n",
      " [2.32777268e-01]\n",
      " [3.92614305e-02]\n",
      " [5.95869720e-02]\n",
      " [1.12133235e-01]\n",
      " [6.59002662e-02]\n",
      " [2.82934219e-01]\n",
      " [1.53042734e-01]\n",
      " [6.32002652e-02]\n",
      " [2.25656033e-01]\n",
      " [2.19941139e-05]\n",
      " [6.88760281e-02]\n",
      " [2.10510910e-01]\n",
      " [2.36650705e-02]\n",
      " [4.11810637e-01]\n",
      " [3.02845240e-03]\n",
      " [1.86811090e-01]\n",
      " [6.98957443e-02]\n",
      " [1.64180994e-04]\n",
      " [1.52263045e-03]\n",
      " [1.06409192e-03]\n",
      " [2.36332417e-05]\n",
      " [3.85046005e-05]\n",
      " [2.67188609e-01]\n",
      " [2.02507764e-01]\n",
      " [3.75956893e-02]\n",
      " [2.28243381e-01]\n",
      " [9.33281183e-02]\n",
      " [1.12709224e-01]\n",
      " [3.13047171e-02]\n",
      " [2.41143197e-01]\n",
      " [3.23355198e-05]\n",
      " [3.44680429e-01]\n",
      " [5.78165948e-02]\n",
      " [6.84043765e-03]\n",
      " [3.59713018e-01]\n",
      " [7.61757195e-02]\n",
      " [1.40823703e-02]\n",
      " [3.09630364e-01]\n",
      " [2.32573390e-01]]\n",
      "Actual: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "43/43 [==============================] - 0s 70us/step\n",
      "Eval: [0.30644641574039017, 0.930232584476471]\n",
      "------------------------------------------------\n",
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5776 - val_loss: 0.6568 - val_accuracy: 0.8718\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.6536 - accuracy: 0.7615 - val_loss: 0.6077 - val_accuracy: 0.8718\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.6205 - accuracy: 0.7557 - val_loss: 0.5332 - val_accuracy: 0.8718\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.5915 - accuracy: 0.7557 - val_loss: 0.4640 - val_accuracy: 0.8718\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.5664 - accuracy: 0.7557 - val_loss: 0.4453 - val_accuracy: 0.8718\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.5553 - accuracy: 0.7557 - val_loss: 0.4387 - val_accuracy: 0.8718\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.5569 - accuracy: 0.7557 - val_loss: 0.4316 - val_accuracy: 0.8718\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.5411 - accuracy: 0.7557 - val_loss: 0.4229 - val_accuracy: 0.8718\n",
      "Epoch 9/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.5361 - accuracy: 0.7557 - val_loss: 0.4140 - val_accuracy: 0.8718\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.5245 - accuracy: 0.7557 - val_loss: 0.4126 - val_accuracy: 0.8718\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.5262 - accuracy: 0.7557 - val_loss: 0.4109 - val_accuracy: 0.8718\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.5231 - accuracy: 0.7557 - val_loss: 0.4058 - val_accuracy: 0.8718\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.5152 - accuracy: 0.7557 - val_loss: 0.3947 - val_accuracy: 0.8718\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.5082 - accuracy: 0.7529 - val_loss: 0.3816 - val_accuracy: 0.8718\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 150us/step - loss: 0.4989 - accuracy: 0.7557 - val_loss: 0.3799 - val_accuracy: 0.8718\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 178us/step - loss: 0.4920 - accuracy: 0.7557 - val_loss: 0.3708 - val_accuracy: 0.8718\n",
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 150us/step - loss: 0.4760 - accuracy: 0.7672 - val_loss: 0.3735 - val_accuracy: 0.8205\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 181us/step - loss: 0.4834 - accuracy: 0.7615 - val_loss: 0.3612 - val_accuracy: 0.8205\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 167us/step - loss: 0.4829 - accuracy: 0.7586 - val_loss: 0.3554 - val_accuracy: 0.8205\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 152us/step - loss: 0.4674 - accuracy: 0.7644 - val_loss: 0.3789 - val_accuracy: 0.7949\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 170us/step - loss: 0.4658 - accuracy: 0.7701 - val_loss: 0.3449 - val_accuracy: 0.8205\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 164us/step - loss: 0.4750 - accuracy: 0.7787 - val_loss: 0.3532 - val_accuracy: 0.8462\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4628 - accuracy: 0.7730 - val_loss: 0.3528 - val_accuracy: 0.8205\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.4633 - accuracy: 0.7730 - val_loss: 0.3528 - val_accuracy: 0.7949\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4656 - accuracy: 0.7644 - val_loss: 0.3458 - val_accuracy: 0.8205\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4489 - accuracy: 0.7701 - val_loss: 0.3531 - val_accuracy: 0.7692\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4514 - accuracy: 0.7816 - val_loss: 0.3455 - val_accuracy: 0.7692\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4478 - accuracy: 0.7960 - val_loss: 0.3467 - val_accuracy: 0.7692\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4561 - accuracy: 0.7615 - val_loss: 0.3505 - val_accuracy: 0.7949\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4552 - accuracy: 0.7759 - val_loss: 0.3481 - val_accuracy: 0.7692\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4458 - accuracy: 0.7902 - val_loss: 0.3503 - val_accuracy: 0.7692\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4664 - accuracy: 0.7759 - val_loss: 0.3507 - val_accuracy: 0.7949\n",
      "Epoch 33/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4637 - accuracy: 0.7730 - val_loss: 0.3581 - val_accuracy: 0.7949\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4538 - accuracy: 0.7471 - val_loss: 0.3416 - val_accuracy: 0.7692\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4446 - accuracy: 0.7701 - val_loss: 0.3359 - val_accuracy: 0.7692\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4603 - accuracy: 0.7902 - val_loss: 0.3616 - val_accuracy: 0.7949\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4588 - accuracy: 0.7816 - val_loss: 0.3359 - val_accuracy: 0.7692\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4576 - accuracy: 0.7816 - val_loss: 0.3494 - val_accuracy: 0.7692\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4456 - accuracy: 0.7902 - val_loss: 0.3325 - val_accuracy: 0.7692\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4609 - accuracy: 0.7816 - val_loss: 0.3459 - val_accuracy: 0.7692\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4570 - accuracy: 0.7730 - val_loss: 0.3451 - val_accuracy: 0.7692\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4505 - accuracy: 0.7759 - val_loss: 0.3393 - val_accuracy: 0.7692\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4465 - accuracy: 0.7730 - val_loss: 0.3410 - val_accuracy: 0.7692\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4429 - accuracy: 0.7759 - val_loss: 0.3352 - val_accuracy: 0.7692\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4495 - accuracy: 0.7730 - val_loss: 0.3502 - val_accuracy: 0.7949\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4396 - accuracy: 0.7586 - val_loss: 0.3430 - val_accuracy: 0.7692\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4545 - accuracy: 0.7644 - val_loss: 0.3378 - val_accuracy: 0.7692\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4560 - accuracy: 0.7701 - val_loss: 0.3442 - val_accuracy: 0.7692\n",
      "Epoch 49/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4537 - accuracy: 0.7759 - val_loss: 0.3435 - val_accuracy: 0.7692\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4577 - accuracy: 0.7615 - val_loss: 0.3458 - val_accuracy: 0.7692\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4388 - accuracy: 0.7816 - val_loss: 0.3358 - val_accuracy: 0.7692\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4656 - accuracy: 0.7701 - val_loss: 0.3359 - val_accuracy: 0.7692\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4580 - accuracy: 0.7672 - val_loss: 0.3491 - val_accuracy: 0.7949\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4463 - accuracy: 0.7845 - val_loss: 0.3365 - val_accuracy: 0.7692\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4514 - accuracy: 0.7701 - val_loss: 0.3300 - val_accuracy: 0.7692\n",
      "Epoch 56/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4552 - accuracy: 0.7816 - val_loss: 0.3404 - val_accuracy: 0.7692\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4479 - accuracy: 0.7845 - val_loss: 0.3471 - val_accuracy: 0.7949\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4472 - accuracy: 0.7701 - val_loss: 0.3443 - val_accuracy: 0.7949\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4459 - accuracy: 0.7759 - val_loss: 0.3363 - val_accuracy: 0.7949\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4471 - accuracy: 0.7845 - val_loss: 0.3289 - val_accuracy: 0.7692\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4504 - accuracy: 0.7845 - val_loss: 0.3551 - val_accuracy: 0.7692\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4421 - accuracy: 0.7759 - val_loss: 0.3329 - val_accuracy: 0.7692\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4508 - accuracy: 0.7701 - val_loss: 0.3347 - val_accuracy: 0.7692\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4359 - accuracy: 0.7759 - val_loss: 0.3427 - val_accuracy: 0.7692\n",
      "Epoch 65/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4449 - accuracy: 0.7787 - val_loss: 0.3394 - val_accuracy: 0.7949\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4507 - accuracy: 0.7960 - val_loss: 0.3394 - val_accuracy: 0.7692\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4387 - accuracy: 0.7902 - val_loss: 0.3410 - val_accuracy: 0.7692\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4461 - accuracy: 0.7902 - val_loss: 0.3465 - val_accuracy: 0.7692\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4485 - accuracy: 0.7759 - val_loss: 0.3388 - val_accuracy: 0.7692\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4410 - accuracy: 0.7902 - val_loss: 0.3334 - val_accuracy: 0.7692\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4376 - accuracy: 0.7816 - val_loss: 0.3363 - val_accuracy: 0.7692\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 95us/step - loss: 0.4418 - accuracy: 0.7816 - val_loss: 0.3424 - val_accuracy: 0.7949\n",
      "Epoch 73/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4376 - accuracy: 0.7874 - val_loss: 0.3475 - val_accuracy: 0.7949\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4382 - accuracy: 0.7816 - val_loss: 0.3372 - val_accuracy: 0.7692\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4473 - accuracy: 0.7931 - val_loss: 0.3494 - val_accuracy: 0.7692\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4400 - accuracy: 0.7845 - val_loss: 0.3417 - val_accuracy: 0.7692\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4359 - accuracy: 0.7787 - val_loss: 0.3448 - val_accuracy: 0.7949\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4446 - accuracy: 0.7845 - val_loss: 0.3640 - val_accuracy: 0.7692\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4306 - accuracy: 0.7845 - val_loss: 0.3511 - val_accuracy: 0.7949\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4405 - accuracy: 0.7960 - val_loss: 0.3441 - val_accuracy: 0.7692\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4276 - accuracy: 0.7902 - val_loss: 0.3412 - val_accuracy: 0.7949\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4343 - accuracy: 0.7787 - val_loss: 0.3443 - val_accuracy: 0.7692\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4378 - accuracy: 0.7989 - val_loss: 0.3533 - val_accuracy: 0.7949\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4381 - accuracy: 0.7960 - val_loss: 0.3611 - val_accuracy: 0.7949\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4328 - accuracy: 0.7960 - val_loss: 0.3554 - val_accuracy: 0.7949\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4444 - accuracy: 0.7787 - val_loss: 0.3486 - val_accuracy: 0.7692\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4357 - accuracy: 0.7931 - val_loss: 0.3598 - val_accuracy: 0.7949\n",
      "Epoch 88/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4309 - accuracy: 0.7960 - val_loss: 0.3484 - val_accuracy: 0.7692\n",
      "Epoch 89/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4266 - accuracy: 0.7960 - val_loss: 0.3372 - val_accuracy: 0.7949\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4272 - accuracy: 0.7931 - val_loss: 0.3566 - val_accuracy: 0.7436\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4294 - accuracy: 0.7816 - val_loss: 0.3494 - val_accuracy: 0.7692\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4228 - accuracy: 0.7845 - val_loss: 0.3408 - val_accuracy: 0.7949\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4323 - accuracy: 0.7960 - val_loss: 0.3441 - val_accuracy: 0.7692\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4297 - accuracy: 0.7989 - val_loss: 0.3627 - val_accuracy: 0.7692\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4345 - accuracy: 0.7931 - val_loss: 0.3437 - val_accuracy: 0.7692\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4352 - accuracy: 0.7730 - val_loss: 0.3522 - val_accuracy: 0.7692\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.4357 - accuracy: 0.7931 - val_loss: 0.3523 - val_accuracy: 0.7692\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4225 - accuracy: 0.7931 - val_loss: 0.3518 - val_accuracy: 0.7436\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4276 - accuracy: 0.7960 - val_loss: 0.3527 - val_accuracy: 0.7692\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4318 - accuracy: 0.7960 - val_loss: 0.3583 - val_accuracy: 0.7692\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4365 - accuracy: 0.8017 - val_loss: 0.3387 - val_accuracy: 0.7949\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4299 - accuracy: 0.7845 - val_loss: 0.3624 - val_accuracy: 0.7436\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4317 - accuracy: 0.7816 - val_loss: 0.3630 - val_accuracy: 0.7949\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4286 - accuracy: 0.8132 - val_loss: 0.3506 - val_accuracy: 0.7692\n",
      "Epoch 105/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4298 - accuracy: 0.7902 - val_loss: 0.3530 - val_accuracy: 0.7436\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4417 - accuracy: 0.7989 - val_loss: 0.3676 - val_accuracy: 0.7692\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4313 - accuracy: 0.7960 - val_loss: 0.3459 - val_accuracy: 0.7692\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4203 - accuracy: 0.8017 - val_loss: 0.3469 - val_accuracy: 0.7949\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4352 - accuracy: 0.7960 - val_loss: 0.3544 - val_accuracy: 0.7436\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4275 - accuracy: 0.7816 - val_loss: 0.3721 - val_accuracy: 0.7692\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4091 - accuracy: 0.8017 - val_loss: 0.3602 - val_accuracy: 0.7436\n",
      "Epoch 112/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4382 - accuracy: 0.7931 - val_loss: 0.3618 - val_accuracy: 0.7436\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4195 - accuracy: 0.8218 - val_loss: 0.3559 - val_accuracy: 0.7692\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4299 - accuracy: 0.7960 - val_loss: 0.3578 - val_accuracy: 0.7436\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4221 - accuracy: 0.7960 - val_loss: 0.3460 - val_accuracy: 0.7692\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4168 - accuracy: 0.7902 - val_loss: 0.3521 - val_accuracy: 0.7692\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4376 - accuracy: 0.7931 - val_loss: 0.3658 - val_accuracy: 0.7436\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4314 - accuracy: 0.8132 - val_loss: 0.3562 - val_accuracy: 0.7436\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4220 - accuracy: 0.7960 - val_loss: 0.3750 - val_accuracy: 0.7692\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4137 - accuracy: 0.7874 - val_loss: 0.3601 - val_accuracy: 0.7436\n",
      "Epoch 121/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4279 - accuracy: 0.7874 - val_loss: 0.3664 - val_accuracy: 0.7436\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4141 - accuracy: 0.7960 - val_loss: 0.3419 - val_accuracy: 0.8462\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4012 - accuracy: 0.8161 - val_loss: 0.3615 - val_accuracy: 0.7436\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4254 - accuracy: 0.8103 - val_loss: 0.3627 - val_accuracy: 0.7436\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4017 - accuracy: 0.8190 - val_loss: 0.3552 - val_accuracy: 0.7436\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4214 - accuracy: 0.7989 - val_loss: 0.3474 - val_accuracy: 0.7949\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4364 - accuracy: 0.8017 - val_loss: 0.3745 - val_accuracy: 0.7436\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 101us/step - loss: 0.4255 - accuracy: 0.7874 - val_loss: 0.3639 - val_accuracy: 0.7949\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4090 - accuracy: 0.8103 - val_loss: 0.3563 - val_accuracy: 0.7436\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4141 - accuracy: 0.7989 - val_loss: 0.3558 - val_accuracy: 0.7436\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4189 - accuracy: 0.7787 - val_loss: 0.3585 - val_accuracy: 0.7436\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4051 - accuracy: 0.8075 - val_loss: 0.3662 - val_accuracy: 0.7436\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4116 - accuracy: 0.8103 - val_loss: 0.3810 - val_accuracy: 0.7436\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4218 - accuracy: 0.7989 - val_loss: 0.3654 - val_accuracy: 0.7436\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4154 - accuracy: 0.8046 - val_loss: 0.3479 - val_accuracy: 0.8205\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4090 - accuracy: 0.7989 - val_loss: 0.3694 - val_accuracy: 0.7436\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4109 - accuracy: 0.7960 - val_loss: 0.3593 - val_accuracy: 0.7436\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4105 - accuracy: 0.7989 - val_loss: 0.3689 - val_accuracy: 0.7436\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4079 - accuracy: 0.7931 - val_loss: 0.3571 - val_accuracy: 0.7692\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4076 - accuracy: 0.8132 - val_loss: 0.3802 - val_accuracy: 0.7436\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4116 - accuracy: 0.8161 - val_loss: 0.3719 - val_accuracy: 0.7436\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4241 - accuracy: 0.7931 - val_loss: 0.3633 - val_accuracy: 0.7692\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4116 - accuracy: 0.7989 - val_loss: 0.3641 - val_accuracy: 0.7692\n",
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4108 - accuracy: 0.8017 - val_loss: 0.3551 - val_accuracy: 0.7949\n",
      "Epoch 145/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4105 - accuracy: 0.8046 - val_loss: 0.3603 - val_accuracy: 0.7692\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4225 - accuracy: 0.7931 - val_loss: 0.3617 - val_accuracy: 0.7692\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4013 - accuracy: 0.8046 - val_loss: 0.3624 - val_accuracy: 0.7692\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4031 - accuracy: 0.8046 - val_loss: 0.3801 - val_accuracy: 0.7436\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4137 - accuracy: 0.8017 - val_loss: 0.3719 - val_accuracy: 0.7692\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3984 - accuracy: 0.8132 - val_loss: 0.3711 - val_accuracy: 0.7692\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3962 - accuracy: 0.8190 - val_loss: 0.3760 - val_accuracy: 0.7436\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4125 - accuracy: 0.8132 - val_loss: 0.3729 - val_accuracy: 0.7949\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4166 - accuracy: 0.8046 - val_loss: 0.3712 - val_accuracy: 0.7692\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4167 - accuracy: 0.8075 - val_loss: 0.3610 - val_accuracy: 0.7949\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4095 - accuracy: 0.8046 - val_loss: 0.3619 - val_accuracy: 0.7949\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4023 - accuracy: 0.8132 - val_loss: 0.3768 - val_accuracy: 0.7692\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4010 - accuracy: 0.8017 - val_loss: 0.3718 - val_accuracy: 0.7949\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4090 - accuracy: 0.8046 - val_loss: 0.3866 - val_accuracy: 0.7949\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4032 - accuracy: 0.8046 - val_loss: 0.3819 - val_accuracy: 0.7692\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4032 - accuracy: 0.8046 - val_loss: 0.3756 - val_accuracy: 0.7692\n",
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4047 - accuracy: 0.8017 - val_loss: 0.3624 - val_accuracy: 0.7949\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3977 - accuracy: 0.8247 - val_loss: 0.3846 - val_accuracy: 0.7436\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4167 - accuracy: 0.8132 - val_loss: 0.3674 - val_accuracy: 0.8205\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3880 - accuracy: 0.8276 - val_loss: 0.3944 - val_accuracy: 0.7436\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3987 - accuracy: 0.8046 - val_loss: 0.3689 - val_accuracy: 0.7692\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4060 - accuracy: 0.8017 - val_loss: 0.3605 - val_accuracy: 0.8205\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4042 - accuracy: 0.7989 - val_loss: 0.3756 - val_accuracy: 0.7692\n",
      "Epoch 168/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4314 - accuracy: 0.7902 - val_loss: 0.3590 - val_accuracy: 0.7692\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3969 - accuracy: 0.8218 - val_loss: 0.3750 - val_accuracy: 0.7692\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3973 - accuracy: 0.8017 - val_loss: 0.3666 - val_accuracy: 0.7692\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4020 - accuracy: 0.8017 - val_loss: 0.3715 - val_accuracy: 0.7949\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4002 - accuracy: 0.8218 - val_loss: 0.3816 - val_accuracy: 0.7692\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3988 - accuracy: 0.8190 - val_loss: 0.3685 - val_accuracy: 0.7949\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4042 - accuracy: 0.7960 - val_loss: 0.3837 - val_accuracy: 0.7692\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3836 - accuracy: 0.8103 - val_loss: 0.3827 - val_accuracy: 0.7692\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3888 - accuracy: 0.8190 - val_loss: 0.3534 - val_accuracy: 0.7949\n",
      "Epoch 177/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3885 - accuracy: 0.8218 - val_loss: 0.3770 - val_accuracy: 0.7692\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4008 - accuracy: 0.8046 - val_loss: 0.3581 - val_accuracy: 0.7949\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.3887 - accuracy: 0.8075 - val_loss: 0.3648 - val_accuracy: 0.7949\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3891 - accuracy: 0.8362 - val_loss: 0.3925 - val_accuracy: 0.7692\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4004 - accuracy: 0.8046 - val_loss: 0.3679 - val_accuracy: 0.7692\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3955 - accuracy: 0.8132 - val_loss: 0.3674 - val_accuracy: 0.7692\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3961 - accuracy: 0.8103 - val_loss: 0.3615 - val_accuracy: 0.7949\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 95us/step - loss: 0.4042 - accuracy: 0.8190 - val_loss: 0.3689 - val_accuracy: 0.7692\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3875 - accuracy: 0.8132 - val_loss: 0.3818 - val_accuracy: 0.7949\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3911 - accuracy: 0.8075 - val_loss: 0.3628 - val_accuracy: 0.7949\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3910 - accuracy: 0.8247 - val_loss: 0.3795 - val_accuracy: 0.7692\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3867 - accuracy: 0.8075 - val_loss: 0.3893 - val_accuracy: 0.7692\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3877 - accuracy: 0.8218 - val_loss: 0.3800 - val_accuracy: 0.7692\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3993 - accuracy: 0.8075 - val_loss: 0.3774 - val_accuracy: 0.7692\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4070 - accuracy: 0.8075 - val_loss: 0.3785 - val_accuracy: 0.7692\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3987 - accuracy: 0.8075 - val_loss: 0.3578 - val_accuracy: 0.7949\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3926 - accuracy: 0.8046 - val_loss: 0.3630 - val_accuracy: 0.7692\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3930 - accuracy: 0.8046 - val_loss: 0.3627 - val_accuracy: 0.7949\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3956 - accuracy: 0.8132 - val_loss: 0.3782 - val_accuracy: 0.7692\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3897 - accuracy: 0.8218 - val_loss: 0.3826 - val_accuracy: 0.7949\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3895 - accuracy: 0.8132 - val_loss: 0.3937 - val_accuracy: 0.7692\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4011 - accuracy: 0.7787 - val_loss: 0.3508 - val_accuracy: 0.8205\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3805 - accuracy: 0.8333 - val_loss: 0.3954 - val_accuracy: 0.7692\n",
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3826 - accuracy: 0.8247 - val_loss: 0.3717 - val_accuracy: 0.7949\n",
      "Predicted: [[7.6375830e-01]\n",
      " [3.6316222e-01]\n",
      " [4.0690482e-01]\n",
      " [3.1843549e-01]\n",
      " [4.3212432e-01]\n",
      " [5.9068203e-05]\n",
      " [1.3722906e-01]\n",
      " [3.8888261e-01]\n",
      " [1.8392169e-01]\n",
      " [3.1353951e-01]\n",
      " [1.9010842e-02]\n",
      " [2.5196433e-02]\n",
      " [8.2544571e-01]\n",
      " [3.2887071e-02]\n",
      " [7.3510408e-04]\n",
      " [2.0275339e-01]\n",
      " [2.8095439e-01]\n",
      " [5.1282209e-01]\n",
      " [7.7752948e-02]\n",
      " [6.5314621e-01]\n",
      " [3.2334328e-03]\n",
      " [6.7484647e-02]\n",
      " [5.1668137e-02]\n",
      " [2.9779789e-01]\n",
      " [7.5193501e-01]\n",
      " [4.3982834e-02]\n",
      " [3.8415471e-01]\n",
      " [1.6453150e-01]\n",
      " [4.6783888e-01]\n",
      " [2.6676103e-01]\n",
      " [2.3569345e-01]\n",
      " [8.3436370e-03]\n",
      " [1.8253505e-02]\n",
      " [1.0760128e-03]\n",
      " [2.0321584e-01]\n",
      " [3.5480103e-01]\n",
      " [3.0628949e-02]\n",
      " [4.5752034e-01]\n",
      " [2.1521196e-01]\n",
      " [2.3970455e-02]\n",
      " [3.0398390e-01]\n",
      " [3.2299313e-01]\n",
      " [3.4893999e-01]]\n",
      "Actual: [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "43/43 [==============================] - 0s 47us/step\n",
      "Eval: [0.44045931655307147, 0.7906976938247681]\n",
      "------------------------------------------------\n",
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 0s 840us/step - loss: 0.6786 - accuracy: 0.6293 - val_loss: 0.6563 - val_accuracy: 0.7179\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.6340 - accuracy: 0.7270 - val_loss: 0.6139 - val_accuracy: 0.7179\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.5911 - accuracy: 0.7270 - val_loss: 0.5920 - val_accuracy: 0.7179\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.5933 - accuracy: 0.7270 - val_loss: 0.5828 - val_accuracy: 0.7179\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.5942 - accuracy: 0.7270 - val_loss: 0.5707 - val_accuracy: 0.7179\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.5663 - accuracy: 0.7270 - val_loss: 0.5576 - val_accuracy: 0.7179\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.5626 - accuracy: 0.7270 - val_loss: 0.5437 - val_accuracy: 0.7179\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.5588 - accuracy: 0.7270 - val_loss: 0.5278 - val_accuracy: 0.7179\n",
      "Epoch 9/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.5401 - accuracy: 0.7270 - val_loss: 0.5131 - val_accuracy: 0.7179\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.5402 - accuracy: 0.7299 - val_loss: 0.4982 - val_accuracy: 0.7179\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.5101 - accuracy: 0.7356 - val_loss: 0.4853 - val_accuracy: 0.7179\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.5170 - accuracy: 0.7299 - val_loss: 0.4745 - val_accuracy: 0.7949\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.5100 - accuracy: 0.7414 - val_loss: 0.4647 - val_accuracy: 0.7949\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.5033 - accuracy: 0.7414 - val_loss: 0.4599 - val_accuracy: 0.7949\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4918 - accuracy: 0.7586 - val_loss: 0.4562 - val_accuracy: 0.7949\n",
      "Epoch 16/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4919 - accuracy: 0.7471 - val_loss: 0.4502 - val_accuracy: 0.7949\n",
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4803 - accuracy: 0.7557 - val_loss: 0.4451 - val_accuracy: 0.7949\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4906 - accuracy: 0.7529 - val_loss: 0.4430 - val_accuracy: 0.7949\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4822 - accuracy: 0.7787 - val_loss: 0.4437 - val_accuracy: 0.7949\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4951 - accuracy: 0.7816 - val_loss: 0.4353 - val_accuracy: 0.7949\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4883 - accuracy: 0.7644 - val_loss: 0.4305 - val_accuracy: 0.8462\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4842 - accuracy: 0.7557 - val_loss: 0.4288 - val_accuracy: 0.8205\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4881 - accuracy: 0.7443 - val_loss: 0.4316 - val_accuracy: 0.8205\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4725 - accuracy: 0.7615 - val_loss: 0.4292 - val_accuracy: 0.7949\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4843 - accuracy: 0.7557 - val_loss: 0.4286 - val_accuracy: 0.8205\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4740 - accuracy: 0.7845 - val_loss: 0.4289 - val_accuracy: 0.7949\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4728 - accuracy: 0.7644 - val_loss: 0.4306 - val_accuracy: 0.8205\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4768 - accuracy: 0.7615 - val_loss: 0.4261 - val_accuracy: 0.7949\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4675 - accuracy: 0.7874 - val_loss: 0.4225 - val_accuracy: 0.8205\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4656 - accuracy: 0.7557 - val_loss: 0.4220 - val_accuracy: 0.8205\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4679 - accuracy: 0.7644 - val_loss: 0.4194 - val_accuracy: 0.8205\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4717 - accuracy: 0.7500 - val_loss: 0.4182 - val_accuracy: 0.8205\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 95us/step - loss: 0.4664 - accuracy: 0.7701 - val_loss: 0.4171 - val_accuracy: 0.7949\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4638 - accuracy: 0.7816 - val_loss: 0.4155 - val_accuracy: 0.8205\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4607 - accuracy: 0.7845 - val_loss: 0.4133 - val_accuracy: 0.7949\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4699 - accuracy: 0.7644 - val_loss: 0.4143 - val_accuracy: 0.7949\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4708 - accuracy: 0.7500 - val_loss: 0.4157 - val_accuracy: 0.8205\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4728 - accuracy: 0.7730 - val_loss: 0.4159 - val_accuracy: 0.8205\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4787 - accuracy: 0.7500 - val_loss: 0.4165 - val_accuracy: 0.8205\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4624 - accuracy: 0.7586 - val_loss: 0.4199 - val_accuracy: 0.8205\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4486 - accuracy: 0.7701 - val_loss: 0.4152 - val_accuracy: 0.8205\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4612 - accuracy: 0.7672 - val_loss: 0.4136 - val_accuracy: 0.8205\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4630 - accuracy: 0.7471 - val_loss: 0.4129 - val_accuracy: 0.7949\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4632 - accuracy: 0.7615 - val_loss: 0.4110 - val_accuracy: 0.8205\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4721 - accuracy: 0.7730 - val_loss: 0.4093 - val_accuracy: 0.7949\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4752 - accuracy: 0.7529 - val_loss: 0.4126 - val_accuracy: 0.8205\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4551 - accuracy: 0.7730 - val_loss: 0.4108 - val_accuracy: 0.8205\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4545 - accuracy: 0.7845 - val_loss: 0.4075 - val_accuracy: 0.8205\n",
      "Epoch 49/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4554 - accuracy: 0.7759 - val_loss: 0.4022 - val_accuracy: 0.8462\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4650 - accuracy: 0.7586 - val_loss: 0.4046 - val_accuracy: 0.8462\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4511 - accuracy: 0.7845 - val_loss: 0.4087 - val_accuracy: 0.8462\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4572 - accuracy: 0.7644 - val_loss: 0.4054 - val_accuracy: 0.7949\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4601 - accuracy: 0.7701 - val_loss: 0.4067 - val_accuracy: 0.8205\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4691 - accuracy: 0.7672 - val_loss: 0.4156 - val_accuracy: 0.7949\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4692 - accuracy: 0.7615 - val_loss: 0.4129 - val_accuracy: 0.8205\n",
      "Epoch 56/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4668 - accuracy: 0.7500 - val_loss: 0.4125 - val_accuracy: 0.8205\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4548 - accuracy: 0.7816 - val_loss: 0.4097 - val_accuracy: 0.8462\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4649 - accuracy: 0.7902 - val_loss: 0.4084 - val_accuracy: 0.8462\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4647 - accuracy: 0.7644 - val_loss: 0.4068 - val_accuracy: 0.8462\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4574 - accuracy: 0.7701 - val_loss: 0.4073 - val_accuracy: 0.8462\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4694 - accuracy: 0.7586 - val_loss: 0.4061 - val_accuracy: 0.8462\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4493 - accuracy: 0.7931 - val_loss: 0.4049 - val_accuracy: 0.8462\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4478 - accuracy: 0.7644 - val_loss: 0.4092 - val_accuracy: 0.8462\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4680 - accuracy: 0.7529 - val_loss: 0.4073 - val_accuracy: 0.8462\n",
      "Epoch 65/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4548 - accuracy: 0.7644 - val_loss: 0.4084 - val_accuracy: 0.8462\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4525 - accuracy: 0.7787 - val_loss: 0.4097 - val_accuracy: 0.8462\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4599 - accuracy: 0.7586 - val_loss: 0.4060 - val_accuracy: 0.8205\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4480 - accuracy: 0.7845 - val_loss: 0.4077 - val_accuracy: 0.8205\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4611 - accuracy: 0.7615 - val_loss: 0.4091 - val_accuracy: 0.8462\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4483 - accuracy: 0.7931 - val_loss: 0.4068 - val_accuracy: 0.8462\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4509 - accuracy: 0.7759 - val_loss: 0.4053 - val_accuracy: 0.8205\n",
      "Epoch 72/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4598 - accuracy: 0.7759 - val_loss: 0.4088 - val_accuracy: 0.8462\n",
      "Epoch 73/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4499 - accuracy: 0.7787 - val_loss: 0.4100 - val_accuracy: 0.8205\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4573 - accuracy: 0.7845 - val_loss: 0.4076 - val_accuracy: 0.8462\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4545 - accuracy: 0.7701 - val_loss: 0.4077 - val_accuracy: 0.8205\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4454 - accuracy: 0.7845 - val_loss: 0.4027 - val_accuracy: 0.8718\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4663 - accuracy: 0.7615 - val_loss: 0.4009 - val_accuracy: 0.8205\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4404 - accuracy: 0.7787 - val_loss: 0.4022 - val_accuracy: 0.8462\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4494 - accuracy: 0.7816 - val_loss: 0.3998 - val_accuracy: 0.8462\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4670 - accuracy: 0.7615 - val_loss: 0.4029 - val_accuracy: 0.8462\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4413 - accuracy: 0.7874 - val_loss: 0.4048 - val_accuracy: 0.8462\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4605 - accuracy: 0.7874 - val_loss: 0.4027 - val_accuracy: 0.8205\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4494 - accuracy: 0.7586 - val_loss: 0.4043 - val_accuracy: 0.8462\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4528 - accuracy: 0.7672 - val_loss: 0.4016 - val_accuracy: 0.8462\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4610 - accuracy: 0.7730 - val_loss: 0.4033 - val_accuracy: 0.8462\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4475 - accuracy: 0.7816 - val_loss: 0.4028 - val_accuracy: 0.8205\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4383 - accuracy: 0.7759 - val_loss: 0.4034 - val_accuracy: 0.8462\n",
      "Epoch 88/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4503 - accuracy: 0.7787 - val_loss: 0.4013 - val_accuracy: 0.8462\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 89us/step - loss: 0.4578 - accuracy: 0.7787 - val_loss: 0.4020 - val_accuracy: 0.8462\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4430 - accuracy: 0.7730 - val_loss: 0.4041 - val_accuracy: 0.8462\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4502 - accuracy: 0.7759 - val_loss: 0.4083 - val_accuracy: 0.8205\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4528 - accuracy: 0.7787 - val_loss: 0.4061 - val_accuracy: 0.8462\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4504 - accuracy: 0.7730 - val_loss: 0.4045 - val_accuracy: 0.8205\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4459 - accuracy: 0.7874 - val_loss: 0.4007 - val_accuracy: 0.8462\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4377 - accuracy: 0.8017 - val_loss: 0.4019 - val_accuracy: 0.8205\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4558 - accuracy: 0.7644 - val_loss: 0.4021 - val_accuracy: 0.8462\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4502 - accuracy: 0.7730 - val_loss: 0.4019 - val_accuracy: 0.8205\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4441 - accuracy: 0.7816 - val_loss: 0.4045 - val_accuracy: 0.8205\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4330 - accuracy: 0.7874 - val_loss: 0.4024 - val_accuracy: 0.8462\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4507 - accuracy: 0.7845 - val_loss: 0.4028 - val_accuracy: 0.8462\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4327 - accuracy: 0.7845 - val_loss: 0.3992 - val_accuracy: 0.8462\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4426 - accuracy: 0.7816 - val_loss: 0.3986 - val_accuracy: 0.8462\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4532 - accuracy: 0.7672 - val_loss: 0.4003 - val_accuracy: 0.8462\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4456 - accuracy: 0.7787 - val_loss: 0.4020 - val_accuracy: 0.8462\n",
      "Epoch 105/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4508 - accuracy: 0.7816 - val_loss: 0.4045 - val_accuracy: 0.8462\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4572 - accuracy: 0.7730 - val_loss: 0.4002 - val_accuracy: 0.8462\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4463 - accuracy: 0.7816 - val_loss: 0.4020 - val_accuracy: 0.8462\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4470 - accuracy: 0.7874 - val_loss: 0.4000 - val_accuracy: 0.8462\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4322 - accuracy: 0.7845 - val_loss: 0.3937 - val_accuracy: 0.8462\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4399 - accuracy: 0.7557 - val_loss: 0.3958 - val_accuracy: 0.8462\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4436 - accuracy: 0.7874 - val_loss: 0.4002 - val_accuracy: 0.8462\n",
      "Epoch 112/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4517 - accuracy: 0.7759 - val_loss: 0.4029 - val_accuracy: 0.8462\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4543 - accuracy: 0.7845 - val_loss: 0.4079 - val_accuracy: 0.8205\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4352 - accuracy: 0.7759 - val_loss: 0.4039 - val_accuracy: 0.8462\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4526 - accuracy: 0.7845 - val_loss: 0.4009 - val_accuracy: 0.8462\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4514 - accuracy: 0.7701 - val_loss: 0.4027 - val_accuracy: 0.8462\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4464 - accuracy: 0.7845 - val_loss: 0.4063 - val_accuracy: 0.8205\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4448 - accuracy: 0.7672 - val_loss: 0.4117 - val_accuracy: 0.8205\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4353 - accuracy: 0.7845 - val_loss: 0.4095 - val_accuracy: 0.8205\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4366 - accuracy: 0.7874 - val_loss: 0.4036 - val_accuracy: 0.8205\n",
      "Epoch 121/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4319 - accuracy: 0.7759 - val_loss: 0.3998 - val_accuracy: 0.8462\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4437 - accuracy: 0.7931 - val_loss: 0.4018 - val_accuracy: 0.8205\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4543 - accuracy: 0.7701 - val_loss: 0.3990 - val_accuracy: 0.8462\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4353 - accuracy: 0.7759 - val_loss: 0.3957 - val_accuracy: 0.8718\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4356 - accuracy: 0.7845 - val_loss: 0.4005 - val_accuracy: 0.8462\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4347 - accuracy: 0.7845 - val_loss: 0.3992 - val_accuracy: 0.8462\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4508 - accuracy: 0.7759 - val_loss: 0.4043 - val_accuracy: 0.8462\n",
      "Epoch 128/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4414 - accuracy: 0.7874 - val_loss: 0.3971 - val_accuracy: 0.8718\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4415 - accuracy: 0.7759 - val_loss: 0.3976 - val_accuracy: 0.8462\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4434 - accuracy: 0.7759 - val_loss: 0.3984 - val_accuracy: 0.8462\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4400 - accuracy: 0.7701 - val_loss: 0.3987 - val_accuracy: 0.8205\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4425 - accuracy: 0.7902 - val_loss: 0.4001 - val_accuracy: 0.8462\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4372 - accuracy: 0.7845 - val_loss: 0.3973 - val_accuracy: 0.8718\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4348 - accuracy: 0.7845 - val_loss: 0.3950 - val_accuracy: 0.8462\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4342 - accuracy: 0.7759 - val_loss: 0.3988 - val_accuracy: 0.8462\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4229 - accuracy: 0.7902 - val_loss: 0.3941 - val_accuracy: 0.8718\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4327 - accuracy: 0.7902 - val_loss: 0.3918 - val_accuracy: 0.8462\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4235 - accuracy: 0.8017 - val_loss: 0.3914 - val_accuracy: 0.8462\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4527 - accuracy: 0.7787 - val_loss: 0.3950 - val_accuracy: 0.8462\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4472 - accuracy: 0.7759 - val_loss: 0.3987 - val_accuracy: 0.8462\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4501 - accuracy: 0.7701 - val_loss: 0.3928 - val_accuracy: 0.8462\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4319 - accuracy: 0.7759 - val_loss: 0.3957 - val_accuracy: 0.8462\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4434 - accuracy: 0.7787 - val_loss: 0.3968 - val_accuracy: 0.8462\n",
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4495 - accuracy: 0.7701 - val_loss: 0.3955 - val_accuracy: 0.8462\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 95us/step - loss: 0.4429 - accuracy: 0.7787 - val_loss: 0.4035 - val_accuracy: 0.8205\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4330 - accuracy: 0.7902 - val_loss: 0.3990 - val_accuracy: 0.8718\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4396 - accuracy: 0.7874 - val_loss: 0.4004 - val_accuracy: 0.8462\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4253 - accuracy: 0.7816 - val_loss: 0.3974 - val_accuracy: 0.8462\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4326 - accuracy: 0.7787 - val_loss: 0.4050 - val_accuracy: 0.8205\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4299 - accuracy: 0.7960 - val_loss: 0.3994 - val_accuracy: 0.8462\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4189 - accuracy: 0.7931 - val_loss: 0.3950 - val_accuracy: 0.8462\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4468 - accuracy: 0.7586 - val_loss: 0.4003 - val_accuracy: 0.8205\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4395 - accuracy: 0.7816 - val_loss: 0.4064 - val_accuracy: 0.8205\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4253 - accuracy: 0.7931 - val_loss: 0.4027 - val_accuracy: 0.8462\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4333 - accuracy: 0.7902 - val_loss: 0.4051 - val_accuracy: 0.8205\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4369 - accuracy: 0.7845 - val_loss: 0.4021 - val_accuracy: 0.8205\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4321 - accuracy: 0.7845 - val_loss: 0.3980 - val_accuracy: 0.8205\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4359 - accuracy: 0.7759 - val_loss: 0.4057 - val_accuracy: 0.8205\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4246 - accuracy: 0.7874 - val_loss: 0.4036 - val_accuracy: 0.7949\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4347 - accuracy: 0.7730 - val_loss: 0.4060 - val_accuracy: 0.7949\n",
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4325 - accuracy: 0.7787 - val_loss: 0.4050 - val_accuracy: 0.8205\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4269 - accuracy: 0.7787 - val_loss: 0.4054 - val_accuracy: 0.8205\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4339 - accuracy: 0.7874 - val_loss: 0.4028 - val_accuracy: 0.8205\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4266 - accuracy: 0.7816 - val_loss: 0.4045 - val_accuracy: 0.7949\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 103us/step - loss: 0.4229 - accuracy: 0.7701 - val_loss: 0.3921 - val_accuracy: 0.8462\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4218 - accuracy: 0.8046 - val_loss: 0.3900 - val_accuracy: 0.8462\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4376 - accuracy: 0.7730 - val_loss: 0.3918 - val_accuracy: 0.8718\n",
      "Epoch 168/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4338 - accuracy: 0.7787 - val_loss: 0.3971 - val_accuracy: 0.8462\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4215 - accuracy: 0.7672 - val_loss: 0.3987 - val_accuracy: 0.8718\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4162 - accuracy: 0.7874 - val_loss: 0.4045 - val_accuracy: 0.8462\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4122 - accuracy: 0.7960 - val_loss: 0.3991 - val_accuracy: 0.8462\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4143 - accuracy: 0.7931 - val_loss: 0.3917 - val_accuracy: 0.8462\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4177 - accuracy: 0.7845 - val_loss: 0.3982 - val_accuracy: 0.8718\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4314 - accuracy: 0.7816 - val_loss: 0.4009 - val_accuracy: 0.8205\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4347 - accuracy: 0.7845 - val_loss: 0.4077 - val_accuracy: 0.8205\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4280 - accuracy: 0.8017 - val_loss: 0.4083 - val_accuracy: 0.8205\n",
      "Epoch 177/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4163 - accuracy: 0.8075 - val_loss: 0.4027 - val_accuracy: 0.8205\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4428 - accuracy: 0.7902 - val_loss: 0.4050 - val_accuracy: 0.8205\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4208 - accuracy: 0.8046 - val_loss: 0.3966 - val_accuracy: 0.8718\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4306 - accuracy: 0.7701 - val_loss: 0.3995 - val_accuracy: 0.8205\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4242 - accuracy: 0.7759 - val_loss: 0.3996 - val_accuracy: 0.8462\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4236 - accuracy: 0.7816 - val_loss: 0.4015 - val_accuracy: 0.8205\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4228 - accuracy: 0.8017 - val_loss: 0.3996 - val_accuracy: 0.8718\n",
      "Epoch 184/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4304 - accuracy: 0.7759 - val_loss: 0.3979 - val_accuracy: 0.8718\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4086 - accuracy: 0.7931 - val_loss: 0.4111 - val_accuracy: 0.7949\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4282 - accuracy: 0.8017 - val_loss: 0.3965 - val_accuracy: 0.8462\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4237 - accuracy: 0.7874 - val_loss: 0.3999 - val_accuracy: 0.8205\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4217 - accuracy: 0.7845 - val_loss: 0.4077 - val_accuracy: 0.7949\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4093 - accuracy: 0.7874 - val_loss: 0.3973 - val_accuracy: 0.8718\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4196 - accuracy: 0.7931 - val_loss: 0.4084 - val_accuracy: 0.8462\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4212 - accuracy: 0.7845 - val_loss: 0.4063 - val_accuracy: 0.8462\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4272 - accuracy: 0.7816 - val_loss: 0.4164 - val_accuracy: 0.7949\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4184 - accuracy: 0.7874 - val_loss: 0.4108 - val_accuracy: 0.7949\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4313 - accuracy: 0.7845 - val_loss: 0.4008 - val_accuracy: 0.8462\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4066 - accuracy: 0.7989 - val_loss: 0.4079 - val_accuracy: 0.8205\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4197 - accuracy: 0.7902 - val_loss: 0.3984 - val_accuracy: 0.8462\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4160 - accuracy: 0.7787 - val_loss: 0.4009 - val_accuracy: 0.8718\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3970 - accuracy: 0.8017 - val_loss: 0.4086 - val_accuracy: 0.7692\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4059 - accuracy: 0.7902 - val_loss: 0.3985 - val_accuracy: 0.8205\n",
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4226 - accuracy: 0.7874 - val_loss: 0.4011 - val_accuracy: 0.8718\n",
      "Predicted: [[3.4965163e-01]\n",
      " [2.6350915e-03]\n",
      " [3.5378763e-01]\n",
      " [4.6202540e-04]\n",
      " [8.5202944e-01]\n",
      " [2.4473667e-04]\n",
      " [1.9391698e-01]\n",
      " [1.9440290e-01]\n",
      " [4.0260658e-01]\n",
      " [1.5172046e-01]\n",
      " [1.3590425e-01]\n",
      " [4.9767742e-01]\n",
      " [2.9814133e-01]\n",
      " [7.3183894e-01]\n",
      " [2.5591946e-01]\n",
      " [5.4737377e-01]\n",
      " [3.3345342e-01]\n",
      " [3.3202481e-01]\n",
      " [3.9732689e-01]\n",
      " [5.9655011e-03]\n",
      " [2.5641918e-04]\n",
      " [2.8289020e-02]\n",
      " [3.0583590e-02]\n",
      " [4.3635958e-01]\n",
      " [7.4954188e-01]\n",
      " [3.6676925e-01]\n",
      " [6.0579580e-01]\n",
      " [1.0046214e-02]\n",
      " [7.5148582e-01]\n",
      " [6.7807102e-01]\n",
      " [3.1376401e-01]\n",
      " [3.9274937e-01]\n",
      " [3.8109297e-01]\n",
      " [1.2682557e-02]\n",
      " [6.5796345e-02]\n",
      " [1.6338468e-02]\n",
      " [3.2659894e-01]\n",
      " [5.3107738e-04]\n",
      " [4.8095742e-01]\n",
      " [5.8563137e-01]\n",
      " [3.0469829e-01]\n",
      " [3.6196029e-04]\n",
      " [9.1807164e-02]]\n",
      "Actual: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 69us/step\n",
      "Eval: [0.8270599537117537, 0.6976743936538696]\n",
      "------------------------------------------------\n",
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 0s 900us/step - loss: 0.5959 - accuracy: 0.9138 - val_loss: 0.4825 - val_accuracy: 0.9744\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3895 - accuracy: 0.9569 - val_loss: 0.2501 - val_accuracy: 0.9744\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2207 - accuracy: 0.9569 - val_loss: 0.1512 - val_accuracy: 0.9744\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1973 - accuracy: 0.9569 - val_loss: 0.1489 - val_accuracy: 0.9744\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1928 - accuracy: 0.9569 - val_loss: 0.1477 - val_accuracy: 0.9744\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1998 - accuracy: 0.9569 - val_loss: 0.1477 - val_accuracy: 0.9744\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1813 - accuracy: 0.9569 - val_loss: 0.1487 - val_accuracy: 0.9744\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1798 - accuracy: 0.9569 - val_loss: 0.1463 - val_accuracy: 0.9744\n",
      "Epoch 9/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1861 - accuracy: 0.9569 - val_loss: 0.1465 - val_accuracy: 0.9744\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1735 - accuracy: 0.9569 - val_loss: 0.1453 - val_accuracy: 0.9744\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1823 - accuracy: 0.9569 - val_loss: 0.1463 - val_accuracy: 0.9744\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1708 - accuracy: 0.9569 - val_loss: 0.1458 - val_accuracy: 0.9744\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1743 - accuracy: 0.9569 - val_loss: 0.1463 - val_accuracy: 0.9744\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1640 - accuracy: 0.9569 - val_loss: 0.1443 - val_accuracy: 0.9744\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1581 - accuracy: 0.9569 - val_loss: 0.1437 - val_accuracy: 0.9744\n",
      "Epoch 16/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1662 - accuracy: 0.9569 - val_loss: 0.1440 - val_accuracy: 0.9744\n",
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1575 - accuracy: 0.9569 - val_loss: 0.1447 - val_accuracy: 0.9744\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1622 - accuracy: 0.9569 - val_loss: 0.1442 - val_accuracy: 0.9744\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1666 - accuracy: 0.9569 - val_loss: 0.1454 - val_accuracy: 0.9744\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1556 - accuracy: 0.9569 - val_loss: 0.1425 - val_accuracy: 0.9744\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1637 - accuracy: 0.9569 - val_loss: 0.1404 - val_accuracy: 0.9744\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1513 - accuracy: 0.9569 - val_loss: 0.1433 - val_accuracy: 0.9744\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1470 - accuracy: 0.9569 - val_loss: 0.1431 - val_accuracy: 0.9744\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1638 - accuracy: 0.9569 - val_loss: 0.1422 - val_accuracy: 0.9744\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1466 - accuracy: 0.9569 - val_loss: 0.1422 - val_accuracy: 0.9744\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1423 - accuracy: 0.9569 - val_loss: 0.1477 - val_accuracy: 0.9744\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1515 - accuracy: 0.9569 - val_loss: 0.1445 - val_accuracy: 0.9744\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1497 - accuracy: 0.9569 - val_loss: 0.1419 - val_accuracy: 0.9744\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1409 - accuracy: 0.9569 - val_loss: 0.1423 - val_accuracy: 0.9744\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1575 - accuracy: 0.9569 - val_loss: 0.1444 - val_accuracy: 0.9744\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1367 - accuracy: 0.9569 - val_loss: 0.1422 - val_accuracy: 0.9744\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1474 - accuracy: 0.9569 - val_loss: 0.1426 - val_accuracy: 0.9744\n",
      "Epoch 33/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1431 - accuracy: 0.9569 - val_loss: 0.1413 - val_accuracy: 0.9744\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1469 - accuracy: 0.9569 - val_loss: 0.1442 - val_accuracy: 0.9744\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1439 - accuracy: 0.9569 - val_loss: 0.1427 - val_accuracy: 0.9744\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1508 - accuracy: 0.9569 - val_loss: 0.1409 - val_accuracy: 0.9744\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1438 - accuracy: 0.9569 - val_loss: 0.1386 - val_accuracy: 0.9744\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1461 - accuracy: 0.9569 - val_loss: 0.1437 - val_accuracy: 0.9744\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1416 - accuracy: 0.9569 - val_loss: 0.1423 - val_accuracy: 0.9744\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1481 - accuracy: 0.9569 - val_loss: 0.1447 - val_accuracy: 0.9744\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1474 - accuracy: 0.9569 - val_loss: 0.1432 - val_accuracy: 0.9744\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1390 - accuracy: 0.9569 - val_loss: 0.1452 - val_accuracy: 0.9744\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1383 - accuracy: 0.9569 - val_loss: 0.1462 - val_accuracy: 0.9744\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1422 - accuracy: 0.9569 - val_loss: 0.1492 - val_accuracy: 0.9744\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1278 - accuracy: 0.9569 - val_loss: 0.1472 - val_accuracy: 0.9744\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1418 - accuracy: 0.9569 - val_loss: 0.1463 - val_accuracy: 0.9744\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1400 - accuracy: 0.9569 - val_loss: 0.1473 - val_accuracy: 0.9744\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1294 - accuracy: 0.9569 - val_loss: 0.1490 - val_accuracy: 0.9744\n",
      "Epoch 49/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1475 - accuracy: 0.9569 - val_loss: 0.1475 - val_accuracy: 0.9744\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1492 - accuracy: 0.9569 - val_loss: 0.1477 - val_accuracy: 0.9744\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1353 - accuracy: 0.9569 - val_loss: 0.1450 - val_accuracy: 0.9744\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1345 - accuracy: 0.9569 - val_loss: 0.1455 - val_accuracy: 0.9744\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1409 - accuracy: 0.9569 - val_loss: 0.1439 - val_accuracy: 0.9744\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1337 - accuracy: 0.9569 - val_loss: 0.1443 - val_accuracy: 0.9744\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.96 - 0s 92us/step - loss: 0.1368 - accuracy: 0.9569 - val_loss: 0.1473 - val_accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1421 - accuracy: 0.9569 - val_loss: 0.1493 - val_accuracy: 0.9744\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1370 - accuracy: 0.9569 - val_loss: 0.1476 - val_accuracy: 0.9744\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1359 - accuracy: 0.9569 - val_loss: 0.1469 - val_accuracy: 0.9744\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1380 - accuracy: 0.9569 - val_loss: 0.1463 - val_accuracy: 0.9744\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1353 - accuracy: 0.9569 - val_loss: 0.1460 - val_accuracy: 0.9744\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1263 - accuracy: 0.9569 - val_loss: 0.1438 - val_accuracy: 0.9744\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1404 - accuracy: 0.9569 - val_loss: 0.1411 - val_accuracy: 0.9744\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1457 - accuracy: 0.9569 - val_loss: 0.1405 - val_accuracy: 0.9744\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1423 - accuracy: 0.9569 - val_loss: 0.1405 - val_accuracy: 0.9744\n",
      "Epoch 65/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1381 - accuracy: 0.9569 - val_loss: 0.1430 - val_accuracy: 0.9744\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1406 - accuracy: 0.9569 - val_loss: 0.1477 - val_accuracy: 0.9744\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1426 - accuracy: 0.9569 - val_loss: 0.1491 - val_accuracy: 0.9744\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1409 - accuracy: 0.9569 - val_loss: 0.1463 - val_accuracy: 0.9744\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1318 - accuracy: 0.9569 - val_loss: 0.1487 - val_accuracy: 0.9744\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1379 - accuracy: 0.9569 - val_loss: 0.1546 - val_accuracy: 0.9744\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1300 - accuracy: 0.9569 - val_loss: 0.1576 - val_accuracy: 0.9744\n",
      "Epoch 72/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1437 - accuracy: 0.9569 - val_loss: 0.1569 - val_accuracy: 0.9744\n",
      "Epoch 73/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1381 - accuracy: 0.9569 - val_loss: 0.1580 - val_accuracy: 0.9744\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1354 - accuracy: 0.9569 - val_loss: 0.1563 - val_accuracy: 0.9744\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1402 - accuracy: 0.9569 - val_loss: 0.1532 - val_accuracy: 0.9744\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1360 - accuracy: 0.9569 - val_loss: 0.1497 - val_accuracy: 0.9744\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1380 - accuracy: 0.9569 - val_loss: 0.1508 - val_accuracy: 0.9744\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.96 - 0s 92us/step - loss: 0.1348 - accuracy: 0.9569 - val_loss: 0.1529 - val_accuracy: 0.9744\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1318 - accuracy: 0.9569 - val_loss: 0.1521 - val_accuracy: 0.9744\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1407 - accuracy: 0.9569 - val_loss: 0.1542 - val_accuracy: 0.9744\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1417 - accuracy: 0.9569 - val_loss: 0.1574 - val_accuracy: 0.9744\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1471 - accuracy: 0.9569 - val_loss: 0.1579 - val_accuracy: 0.9744\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1296 - accuracy: 0.9569 - val_loss: 0.1543 - val_accuracy: 0.9744\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1447 - accuracy: 0.9569 - val_loss: 0.1563 - val_accuracy: 0.9744\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1323 - accuracy: 0.9569 - val_loss: 0.1547 - val_accuracy: 0.9744\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1441 - accuracy: 0.9569 - val_loss: 0.1586 - val_accuracy: 0.9744\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1303 - accuracy: 0.9569 - val_loss: 0.1608 - val_accuracy: 0.9744\n",
      "Epoch 88/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1432 - accuracy: 0.9569 - val_loss: 0.1585 - val_accuracy: 0.9744\n",
      "Epoch 89/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1310 - accuracy: 0.9569 - val_loss: 0.1593 - val_accuracy: 0.9744\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1227 - accuracy: 0.9569 - val_loss: 0.1561 - val_accuracy: 0.9744\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1372 - accuracy: 0.9569 - val_loss: 0.1484 - val_accuracy: 0.9744\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1346 - accuracy: 0.9569 - val_loss: 0.1541 - val_accuracy: 0.9744\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1317 - accuracy: 0.9569 - val_loss: 0.1561 - val_accuracy: 0.9744\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1362 - accuracy: 0.9569 - val_loss: 0.1585 - val_accuracy: 0.9744\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1290 - accuracy: 0.9569 - val_loss: 0.1571 - val_accuracy: 0.9744\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1373 - accuracy: 0.9569 - val_loss: 0.1540 - val_accuracy: 0.9744\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1350 - accuracy: 0.9569 - val_loss: 0.1571 - val_accuracy: 0.9744\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1365 - accuracy: 0.9569 - val_loss: 0.1532 - val_accuracy: 0.9744\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1395 - accuracy: 0.9569 - val_loss: 0.1528 - val_accuracy: 0.9744\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1361 - accuracy: 0.9569 - val_loss: 0.1546 - val_accuracy: 0.9744\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1333 - accuracy: 0.9569 - val_loss: 0.1596 - val_accuracy: 0.9744\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1394 - accuracy: 0.9569 - val_loss: 0.1595 - val_accuracy: 0.9744\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1367 - accuracy: 0.9569 - val_loss: 0.1629 - val_accuracy: 0.9744\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1355 - accuracy: 0.9569 - val_loss: 0.1609 - val_accuracy: 0.9744\n",
      "Epoch 105/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1332 - accuracy: 0.9569 - val_loss: 0.1570 - val_accuracy: 0.9744\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1340 - accuracy: 0.9569 - val_loss: 0.1593 - val_accuracy: 0.9744\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1377 - accuracy: 0.9569 - val_loss: 0.1597 - val_accuracy: 0.9744\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1321 - accuracy: 0.9569 - val_loss: 0.1581 - val_accuracy: 0.9744\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1376 - accuracy: 0.9569 - val_loss: 0.1526 - val_accuracy: 0.9744\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1266 - accuracy: 0.9569 - val_loss: 0.1528 - val_accuracy: 0.9744\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1305 - accuracy: 0.9569 - val_loss: 0.1527 - val_accuracy: 0.9744\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 86us/step - loss: 0.1290 - accuracy: 0.9569 - val_loss: 0.1592 - val_accuracy: 0.9744\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1481 - accuracy: 0.9569 - val_loss: 0.1646 - val_accuracy: 0.9744\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1290 - accuracy: 0.9569 - val_loss: 0.1615 - val_accuracy: 0.9744\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1272 - accuracy: 0.9569 - val_loss: 0.1583 - val_accuracy: 0.9744\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1321 - accuracy: 0.9569 - val_loss: 0.1567 - val_accuracy: 0.9744\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1411 - accuracy: 0.9569 - val_loss: 0.1615 - val_accuracy: 0.9744\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1278 - accuracy: 0.9569 - val_loss: 0.1620 - val_accuracy: 0.9744\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1347 - accuracy: 0.9569 - val_loss: 0.1601 - val_accuracy: 0.9744\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1288 - accuracy: 0.9569 - val_loss: 0.1601 - val_accuracy: 0.9744\n",
      "Epoch 121/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1393 - accuracy: 0.9569 - val_loss: 0.1651 - val_accuracy: 0.9744\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1312 - accuracy: 0.9569 - val_loss: 0.1634 - val_accuracy: 0.9744\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1362 - accuracy: 0.9569 - val_loss: 0.1540 - val_accuracy: 0.9744\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1289 - accuracy: 0.9569 - val_loss: 0.1548 - val_accuracy: 0.9744\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1298 - accuracy: 0.9569 - val_loss: 0.1645 - val_accuracy: 0.9744\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1262 - accuracy: 0.9569 - val_loss: 0.1643 - val_accuracy: 0.9744\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1496 - accuracy: 0.9569 - val_loss: 0.1646 - val_accuracy: 0.9744\n",
      "Epoch 128/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1315 - accuracy: 0.9569 - val_loss: 0.1690 - val_accuracy: 0.9744\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1345 - accuracy: 0.9569 - val_loss: 0.1673 - val_accuracy: 0.9744\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1276 - accuracy: 0.9569 - val_loss: 0.1669 - val_accuracy: 0.9744\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1362 - accuracy: 0.9569 - val_loss: 0.1689 - val_accuracy: 0.9744\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1311 - accuracy: 0.9569 - val_loss: 0.1629 - val_accuracy: 0.9744\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1319 - accuracy: 0.9569 - val_loss: 0.1601 - val_accuracy: 0.9744\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1319 - accuracy: 0.9569 - val_loss: 0.1615 - val_accuracy: 0.9744\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1427 - accuracy: 0.9569 - val_loss: 0.1634 - val_accuracy: 0.9744\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1230 - accuracy: 0.9569 - val_loss: 0.1634 - val_accuracy: 0.9744\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1398 - accuracy: 0.9569 - val_loss: 0.1680 - val_accuracy: 0.9744\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1343 - accuracy: 0.9569 - val_loss: 0.1688 - val_accuracy: 0.9744\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1279 - accuracy: 0.9569 - val_loss: 0.1633 - val_accuracy: 0.9744\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1324 - accuracy: 0.9569 - val_loss: 0.1659 - val_accuracy: 0.9744\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1320 - accuracy: 0.9569 - val_loss: 0.1652 - val_accuracy: 0.9744\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1269 - accuracy: 0.9569 - val_loss: 0.1637 - val_accuracy: 0.9744\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1294 - accuracy: 0.9569 - val_loss: 0.1608 - val_accuracy: 0.9744\n",
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1357 - accuracy: 0.9569 - val_loss: 0.1651 - val_accuracy: 0.9744\n",
      "Epoch 145/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1341 - accuracy: 0.9569 - val_loss: 0.1627 - val_accuracy: 0.9744\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1271 - accuracy: 0.9569 - val_loss: 0.1663 - val_accuracy: 0.9744\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1380 - accuracy: 0.9569 - val_loss: 0.1683 - val_accuracy: 0.9744\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1300 - accuracy: 0.9569 - val_loss: 0.1662 - val_accuracy: 0.9744\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1222 - accuracy: 0.9569 - val_loss: 0.1683 - val_accuracy: 0.9744\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1255 - accuracy: 0.9569 - val_loss: 0.1734 - val_accuracy: 0.9744\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1275 - accuracy: 0.9569 - val_loss: 0.1705 - val_accuracy: 0.9744\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1269 - accuracy: 0.9569 - val_loss: 0.1663 - val_accuracy: 0.9744\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1268 - accuracy: 0.9569 - val_loss: 0.1639 - val_accuracy: 0.9744\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1413 - accuracy: 0.9569 - val_loss: 0.1599 - val_accuracy: 0.9744\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1290 - accuracy: 0.9569 - val_loss: 0.1613 - val_accuracy: 0.9744\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1336 - accuracy: 0.9569 - val_loss: 0.1667 - val_accuracy: 0.9744\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1332 - accuracy: 0.9569 - val_loss: 0.1688 - val_accuracy: 0.9744\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1448 - accuracy: 0.9569 - val_loss: 0.1755 - val_accuracy: 0.9744\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1280 - accuracy: 0.9569 - val_loss: 0.1777 - val_accuracy: 0.9744\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1360 - accuracy: 0.9569 - val_loss: 0.1761 - val_accuracy: 0.9744\n",
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1395 - accuracy: 0.9569 - val_loss: 0.1697 - val_accuracy: 0.9744\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1366 - accuracy: 0.9569 - val_loss: 0.1737 - val_accuracy: 0.9744\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1420 - accuracy: 0.9569 - val_loss: 0.1765 - val_accuracy: 0.9744\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1425 - accuracy: 0.9569 - val_loss: 0.1723 - val_accuracy: 0.9744\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1342 - accuracy: 0.9569 - val_loss: 0.1709 - val_accuracy: 0.9744\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1320 - accuracy: 0.9569 - val_loss: 0.1692 - val_accuracy: 0.9744\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1328 - accuracy: 0.9569 - val_loss: 0.1736 - val_accuracy: 0.9744\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 98us/step - loss: 0.1350 - accuracy: 0.9569 - val_loss: 0.1715 - val_accuracy: 0.9744\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1315 - accuracy: 0.9569 - val_loss: 0.1733 - val_accuracy: 0.9744\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1344 - accuracy: 0.9569 - val_loss: 0.1741 - val_accuracy: 0.9744\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1303 - accuracy: 0.9569 - val_loss: 0.1731 - val_accuracy: 0.9744\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1243 - accuracy: 0.9569 - val_loss: 0.1716 - val_accuracy: 0.9744\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1227 - accuracy: 0.9569 - val_loss: 0.1717 - val_accuracy: 0.9744\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1364 - accuracy: 0.9569 - val_loss: 0.1780 - val_accuracy: 0.9744\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1270 - accuracy: 0.9569 - val_loss: 0.1752 - val_accuracy: 0.9744\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1357 - accuracy: 0.9569 - val_loss: 0.1783 - val_accuracy: 0.9744\n",
      "Epoch 177/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1334 - accuracy: 0.9569 - val_loss: 0.1770 - val_accuracy: 0.9744\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1269 - accuracy: 0.9569 - val_loss: 0.1726 - val_accuracy: 0.9744\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.96 - 0s 92us/step - loss: 0.1387 - accuracy: 0.9569 - val_loss: 0.1664 - val_accuracy: 0.9744\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1306 - accuracy: 0.9569 - val_loss: 0.1686 - val_accuracy: 0.9744\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1208 - accuracy: 0.9569 - val_loss: 0.1736 - val_accuracy: 0.9744\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1261 - accuracy: 0.9569 - val_loss: 0.1752 - val_accuracy: 0.9744\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1239 - accuracy: 0.9569 - val_loss: 0.1775 - val_accuracy: 0.9744\n",
      "Epoch 184/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1337 - accuracy: 0.9569 - val_loss: 0.1863 - val_accuracy: 0.9744\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1295 - accuracy: 0.9569 - val_loss: 0.1803 - val_accuracy: 0.9744\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1269 - accuracy: 0.9569 - val_loss: 0.1794 - val_accuracy: 0.9744\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1280 - accuracy: 0.9569 - val_loss: 0.1769 - val_accuracy: 0.9744\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1320 - accuracy: 0.9569 - val_loss: 0.1782 - val_accuracy: 0.9744\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1412 - accuracy: 0.9569 - val_loss: 0.1798 - val_accuracy: 0.9744\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1201 - accuracy: 0.9569 - val_loss: 0.1837 - val_accuracy: 0.9744\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1232 - accuracy: 0.9569 - val_loss: 0.1786 - val_accuracy: 0.9744\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1228 - accuracy: 0.9569 - val_loss: 0.1779 - val_accuracy: 0.9744\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1372 - accuracy: 0.9569 - val_loss: 0.1785 - val_accuracy: 0.9744\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1299 - accuracy: 0.9569 - val_loss: 0.1856 - val_accuracy: 0.9744\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1337 - accuracy: 0.9569 - val_loss: 0.1917 - val_accuracy: 0.9744\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1374 - accuracy: 0.9569 - val_loss: 0.1825 - val_accuracy: 0.9744\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1372 - accuracy: 0.9569 - val_loss: 0.1783 - val_accuracy: 0.9744\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1334 - accuracy: 0.9569 - val_loss: 0.1779 - val_accuracy: 0.9744\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1334 - accuracy: 0.9569 - val_loss: 0.1812 - val_accuracy: 0.9744\n",
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1337 - accuracy: 0.9569 - val_loss: 0.1846 - val_accuracy: 0.9744\n",
      "Predicted: [[1.6255039e-01]\n",
      " [5.8671832e-04]\n",
      " [1.5042394e-02]\n",
      " [1.4901161e-07]\n",
      " [2.0176172e-05]\n",
      " [1.6724765e-03]\n",
      " [9.1791153e-06]\n",
      " [4.9430132e-03]\n",
      " [0.0000000e+00]\n",
      " [2.2726178e-02]\n",
      " [4.7721267e-03]\n",
      " [1.1920929e-07]\n",
      " [5.5640936e-05]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [9.4935179e-02]\n",
      " [1.7088848e-01]\n",
      " [2.6041022e-01]\n",
      " [1.3591164e-01]\n",
      " [1.2162328e-04]\n",
      " [3.3915043e-05]\n",
      " [0.0000000e+00]\n",
      " [2.8848648e-05]\n",
      " [3.9498210e-03]\n",
      " [1.0415733e-02]\n",
      " [3.9041042e-06]\n",
      " [1.1278927e-02]\n",
      " [1.1905134e-03]\n",
      " [2.2064540e-01]\n",
      " [6.2435865e-05]\n",
      " [1.5050173e-05]\n",
      " [2.6822090e-07]\n",
      " [9.3899012e-02]\n",
      " [5.8710575e-06]\n",
      " [7.5770020e-03]\n",
      " [6.6488981e-05]\n",
      " [0.0000000e+00]\n",
      " [7.1637094e-02]\n",
      " [2.2074613e-01]\n",
      " [1.5228987e-05]\n",
      " [2.3500566e-01]\n",
      " [8.7121343e-03]\n",
      " [1.6847973e-05]]\n",
      "Actual: [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "43/43 [==============================] - 0s 46us/step\n",
      "Eval: [0.5917100892510525, 0.8372092843055725]\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "targets=[target_1,target_2,target_3,target_4]\n",
    "weights=['P1_compliactions_nephropathy.h5','P1_compliactions_retinopathy.h5','P1_compliactions_neuropathy.h5','P1_compliactions_foot_ulcer.h5']\n",
    "for i,target in enumerate(targets):\n",
    "    model=load_model()\n",
    "    #target=np_utils.to_categorical(target)\n",
    "    train_data, test_data, train_target, test_target = train_test_split(xscale, target,test_size=0.1)\n",
    "    history=model.fit(train_data,train_target,epochs=200,validation_split=0.1)\n",
    "    model.save_weights(weights[i])\n",
    "    plot(weights[i])\n",
    "    result=model.predict(test_data)\n",
    "    print('Predicted:',result)\n",
    "    print('Actual:',test_target)\n",
    "    print('Eval:',model.evaluate(test_data,test_target))\n",
    "    print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6255039e-01]\n",
      " [5.8671832e-04]\n",
      " [1.5042394e-02]\n",
      " [1.4901161e-07]\n",
      " [2.0176172e-05]\n",
      " [1.6724765e-03]\n",
      " [9.1791153e-06]\n",
      " [4.9430132e-03]\n",
      " [0.0000000e+00]\n",
      " [2.2726178e-02]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(test_data)\n",
    "\n",
    "print(results[:10])\n",
    "print(test_target[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Diabetic Risk Level\n",
    "\n",
    "### inputs\n",
    "\n",
    "Age (y)\tGender(1, male; 2, female)\theight(cm)\tweight(kg)\tBMI(kg/m2)\tSBP(mmHg)\tDBP(mmHg)\tFPG (mmol/L)\tCholesterol(mmol/L)\tTriglyceride(mmol/L)\tHDL-c(mmol/L)\tLDL(mmol/L)\tALT(U/L)\tAST(U/L)\tBUN(mmol/L)\tCCR(umol/L)\tFPG of final visit(mmol/L)\tyear of followup\tsmoking status(1,current smoker;2, ever smoker;3,never smoker)\tdrinking status(1,current drinker;2, ever drinker;3,never drinker)\tfamily histroy of diabetes(1,Yes;0,No)\n",
    "\n",
    "### Output\n",
    "\n",
    "Probabilities (Out of 100%)\n",
    "\n",
    "censor of diabetes at followup(Out of 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in greater\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014841880160314964 211833\n",
      "[[ 43.     1.   166.4   53.5   96.    57.     5.13   0.78    nan    nan\n",
      "    3.     3.     1.  ]\n",
      " [ 34.     0.   169.    57.   124.    69.     4.61   1.75   1.09   3.13\n",
      "     nan    nan   0.  ]\n",
      " [ 32.     1.   157.    51.    98.    68.     4.73   0.47    nan    nan\n",
      "     nan    nan   0.  ]\n",
      " [ 59.     0.   165.    63.   136.    73.     4.5    0.75   1.53   2.8\n",
      "    3.     3.     0.  ]\n",
      " [ 30.     1.   163.5   48.5  107.    76.     3.48   0.52   1.55   1.43\n",
      "     nan    nan   0.  ]]\n",
      "[4.97 5.5  4.9  5.5  4.82]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset=pd.read_csv('risk_predict.csv').values\n",
    "data=dataset[:,0:13]\n",
    "fpg=dataset[:,13]\n",
    "\n",
    "target= fpg>7\n",
    "target=target.astype(int)\n",
    "\n",
    "print(np.count_nonzero(target)/len(target),len(target))\n",
    "\n",
    "print(data[:5])\n",
    "print(fpg[:5])\n",
    "print(target[:5])\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "imp=SimpleImputer(strategy='median') #or median, most frequent etc.\n",
    "\n",
    "data=imp.fit_transform(data)\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(data)\n",
    "xscale=scaler_x.transform(data)\n",
    "np.save('data_diabetic_risk',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \n",
    "    import keras.models as models\n",
    "    import keras.layers as layers\n",
    "    import keras.optimizers as optimizers\n",
    "    from keras.layers import Dropout\n",
    "    import numpy as np\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171584 samples, validate on 19065 samples\n",
      "Epoch 1/50\n",
      "171584/171584 [==============================] - 13s 77us/step - loss: 0.0736 - accuracy: 0.9850 - val_loss: 0.0691 - val_accuracy: 0.9853\n",
      "Epoch 2/50\n",
      "171584/171584 [==============================] - 13s 76us/step - loss: 0.0685 - accuracy: 0.9852 - val_loss: 0.0669 - val_accuracy: 0.9853\n",
      "Epoch 3/50\n",
      "171584/171584 [==============================] - 13s 77us/step - loss: 0.0675 - accuracy: 0.9852 - val_loss: 0.0655 - val_accuracy: 0.9853\n",
      "Epoch 4/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0675 - accuracy: 0.9852 - val_loss: 0.0655 - val_accuracy: 0.9853\n",
      "Epoch 5/50\n",
      "171584/171584 [==============================] - 14s 80us/step - loss: 0.0673 - accuracy: 0.9852 - val_loss: 0.0660 - val_accuracy: 0.9853\n",
      "Epoch 6/50\n",
      "171584/171584 [==============================] - 13s 78us/step - loss: 0.0670 - accuracy: 0.9852 - val_loss: 0.0654 - val_accuracy: 0.9853\n",
      "Epoch 7/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0672 - accuracy: 0.9852 - val_loss: 0.0672 - val_accuracy: 0.9853\n",
      "Epoch 8/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0672 - accuracy: 0.9852 - val_loss: 0.0653 - val_accuracy: 0.9853\n",
      "Epoch 9/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0670 - accuracy: 0.9852 - val_loss: 0.0703 - val_accuracy: 0.9853\n",
      "Epoch 10/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0669 - accuracy: 0.9852 - val_loss: 0.0655 - val_accuracy: 0.9853\n",
      "Epoch 11/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0668 - accuracy: 0.9852 - val_loss: 0.0651 - val_accuracy: 0.9853\n",
      "Epoch 12/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0669 - accuracy: 0.9852 - val_loss: 0.0661 - val_accuracy: 0.9853\n",
      "Epoch 13/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0667 - accuracy: 0.9852 - val_loss: 0.0653 - val_accuracy: 0.9853\n",
      "Epoch 14/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0668 - accuracy: 0.9852 - val_loss: 0.0653 - val_accuracy: 0.9853\n",
      "Epoch 15/50\n",
      "171584/171584 [==============================] - 14s 80us/step - loss: 0.0668 - accuracy: 0.9852 - val_loss: 0.0659 - val_accuracy: 0.9853\n",
      "Epoch 16/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0668 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 17/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0665 - accuracy: 0.9852 - val_loss: 0.0660 - val_accuracy: 0.9853\n",
      "Epoch 18/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0665 - accuracy: 0.9852 - val_loss: 0.0653 - val_accuracy: 0.9853\n",
      "Epoch 19/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0664 - accuracy: 0.9852 - val_loss: 0.0651 - val_accuracy: 0.9853\n",
      "Epoch 20/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0662 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 21/50\n",
      "171584/171584 [==============================] - 14s 80us/step - loss: 0.0663 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 22/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0662 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 23/50\n",
      "171584/171584 [==============================] - 16s 96us/step - loss: 0.0663 - accuracy: 0.9852 - val_loss: 0.0661 - val_accuracy: 0.9853\n",
      "Epoch 24/50\n",
      "171584/171584 [==============================] - 18s 105us/step - loss: 0.0665 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9853\n",
      "Epoch 25/50\n",
      "171584/171584 [==============================] - 13s 74us/step - loss: 0.0664 - accuracy: 0.9852 - val_loss: 0.0651 - val_accuracy: 0.9853\n",
      "Epoch 26/50\n",
      "171584/171584 [==============================] - 13s 75us/step - loss: 0.0661 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 27/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9853\n",
      "Epoch 28/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0661 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9853\n",
      "Epoch 29/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0659 - accuracy: 0.9852 - val_loss: 0.0647 - val_accuracy: 0.9853\n",
      "Epoch 30/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0661 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 31/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0657 - val_accuracy: 0.9853\n",
      "Epoch 32/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 33/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0659 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 34/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0658 - accuracy: 0.9852 - val_loss: 0.0651 - val_accuracy: 0.9853\n",
      "Epoch 35/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0657 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 36/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0658 - accuracy: 0.9852 - val_loss: 0.0655 - val_accuracy: 0.9853\n",
      "Epoch 37/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0659 - accuracy: 0.9852 - val_loss: 0.0647 - val_accuracy: 0.9853\n",
      "Epoch 38/50\n",
      "171584/171584 [==============================] - 13s 75us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0647 - val_accuracy: 0.9853\n",
      "Epoch 39/50\n",
      "171584/171584 [==============================] - 15s 90us/step - loss: 0.0663 - accuracy: 0.9852 - val_loss: 0.0654 - val_accuracy: 0.9853\n",
      "Epoch 40/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9853\n",
      "Epoch 41/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0648 - val_accuracy: 0.9853\n",
      "Epoch 42/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9853\n",
      "Epoch 43/50\n",
      "171584/171584 [==============================] - 12s 71us/step - loss: 0.0658 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 44/50\n",
      "171584/171584 [==============================] - 12s 71us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9853\n",
      "Epoch 45/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0658 - accuracy: 0.9852 - val_loss: 0.0655 - val_accuracy: 0.9853\n",
      "Epoch 46/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0650 - val_accuracy: 0.9853\n",
      "Epoch 47/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0659 - accuracy: 0.9852 - val_loss: 0.0648 - val_accuracy: 0.9853\n",
      "Epoch 48/50\n",
      "171584/171584 [==============================] - 12s 71us/step - loss: 0.0660 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9853\n",
      "Epoch 49/50\n",
      "171584/171584 [==============================] - 13s 76us/step - loss: 0.0659 - accuracy: 0.9852 - val_loss: 0.0648 - val_accuracy: 0.9853\n",
      "Epoch 50/50\n",
      "171584/171584 [==============================] - 16s 91us/step - loss: 0.0658 - accuracy: 0.9852 - val_loss: 0.0651 - val_accuracy: 0.9853\n",
      "Predicted: [[0.01435348]\n",
      " [0.05693793]\n",
      " [0.01484114]\n",
      " ...\n",
      " [0.01968917]\n",
      " [0.00127846]\n",
      " [0.03382754]]\n",
      "Actual: [0 0 0 ... 0 0 0]\n",
      "21184/21184 [==============================] - 0s 21us/step\n",
      "Eval: [0.06450961048861127, 0.9850358963012695]\n"
     ]
    }
   ],
   "source": [
    "model=load_model()\n",
    "#target=np_utils.to_categorical(target)\n",
    "train_data, test_data, train_target, test_target = train_test_split(xscale, target,test_size=0.1)\n",
    "history=model.fit(train_data,train_target,epochs=50,validation_split=0.1)\n",
    "model.save_weights('P1_Diabetic_Risk.h5')\n",
    "plot('P1_Diabetic_Risk.h5')\n",
    "result=model.predict(test_data)\n",
    "print('Predicted:',result)\n",
    "print('Actual:',test_target)\n",
    "print('Eval:',model.evaluate(test_data,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07290411]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data[2301].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Meal Plan\n",
    "\n",
    "### Inputs\n",
    "gender\tage\tbmi\trisk level\n",
    "### Outputs\n",
    "Meal Plan (1-8 Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Target: [8. 1. 4. 4. 5. 4. 6. 3. 8. 7. 3. 8. 5. 1. 2. 2. 3. 2. 3. 1. 4. 6. 1. 2.\n",
      " 1. 6. 1. 4. 8. 1. 5. 3. 7. 5. 1. 1. 2. 4. 1. 5. 5. 6. 7. 6. 2. 5. 6. 8.\n",
      " 6. 5. 6. 3. 7. 3. 2. 4. 3. 6. 3. 7. 5. 3. 5. 7. 4. 7. 3. 7. 8. 7. 2. 1.\n",
      " 1. 2. 4. 4. 7.]\n",
      "Predicted Target: [8. 1. 4. 4. 5. 4. 6. 3. 8. 7. 3. 4. 5. 1. 2. 2. 3. 2. 3. 1. 4. 6. 1. 2.\n",
      " 1. 6. 1. 4. 8. 1. 5. 3. 7. 5. 1. 1. 2. 4. 1. 5. 5. 6. 7. 6. 2. 5. 6. 6.\n",
      " 6. 5. 6. 3. 7. 4. 2. 2. 3. 6. 3. 7. 5. 3. 5. 7. 4. 7. 3. 7. 8. 7. 2. 1.\n",
      " 1. 2. 4. 4. 7.]\n",
      "Accuracy: 0.948051948051948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2_meal_plan.sav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset=pd.read_csv('mealplan2.csv').values\n",
    "\n",
    "data=dataset[:,0:4]\n",
    "target=dataset[:,4]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#dataset splitting function\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "algorithm=SVC(kernel='linear')\n",
    "#loading the KNN algorithm into \"algorithm\"\n",
    "\n",
    "algorithm.fit(train_data,train_target)\n",
    "#training\n",
    "\n",
    "result=algorithm.predict(test_data)\n",
    "#testing\n",
    "\n",
    "print('Actual Target:',test_target)\n",
    "print('Predicted Target:',result)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc=accuracy_score(test_target,result)\n",
    "\n",
    "print('Accuracy:',acc)\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(algorithm,'2_meal_plan.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Activity Suggestion\n",
    "### Inputs\n",
    "Gender\tAge\tEmployement status\tWorking hours\tFree time in hours\tSleeping hours\tFamily time\tOther illnesses\tEmotional \n",
    "\n",
    "### Outputs\n",
    "Suggestions (Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Target: [0. 0. 0. 0. 0. 0. 1. 2. 2. 0. 1. 0. 0. 2. 0. 0. 2. 2. 0. 2. 2. 2. 0. 2.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 2. 1. 2. 0. 2. 2. 2. 2. 0. 2. 1.\n",
      " 2. 2. 2. 1. 0. 2. 2. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 2. 2. 0. 2. 0. 0. 2. 1. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0.\n",
      " 0. 1. 2. 0. 0. 2. 2. 0. 0. 0. 2. 2. 2. 0. 2. 0. 0. 1. 0. 0. 2. 0. 0. 0.\n",
      " 1. 0. 0. 0. 2. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2. 1. 0. 0. 2. 0. 0. 1. 1. 2.\n",
      " 0. 0. 0. 1. 2. 2. 2. 1. 0. 0. 0. 0. 0. 1. 2. 1. 0. 0. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 2. 0. 1. 0. 0. 0. 2. 2. 0. 2. 2. 0. 2. 2. 1. 1. 2. 0. 0. 2. 1.\n",
      " 0. 0. 2. 0. 2.]\n",
      "Predicted Target: [0. 0. 0. 0. 0. 0. 1. 2. 2. 0. 1. 0. 0. 2. 0. 0. 2. 2. 0. 2. 2. 2. 0. 2.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 2. 1. 2. 0. 2. 2. 2. 2. 0. 2. 1.\n",
      " 2. 2. 2. 1. 0. 2. 2. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 2. 2. 0. 2. 0. 0. 2. 1. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0.\n",
      " 0. 1. 2. 0. 0. 2. 2. 0. 0. 0. 2. 2. 2. 0. 2. 0. 0. 1. 0. 0. 2. 0. 0. 0.\n",
      " 1. 0. 0. 0. 2. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2. 1. 0. 0. 2. 0. 0. 1. 1. 2.\n",
      " 0. 0. 0. 1. 2. 2. 2. 1. 0. 0. 0. 0. 0. 1. 2. 1. 0. 0. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 2. 0. 1. 0. 0. 0. 2. 2. 0. 2. 2. 0. 2. 2. 1. 1. 2. 0. 0. 2. 1.\n",
      " 0. 0. 2. 0. 2.]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4_activity_suggestion.sav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset=pd.read_csv('depression servey-new(30th of march).csv').values\n",
    "\n",
    "data=dataset[:,0:10]\n",
    "target=dataset[:,10]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#dataset splitting function\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "algorithm=SVC(kernel='linear')\n",
    "#loading the KNN algorithm into \"algorithm\"\n",
    "\n",
    "algorithm.fit(train_data,train_target)\n",
    "#training\n",
    "\n",
    "result=algorithm.predict(test_data)\n",
    "#testing\n",
    "\n",
    "print('Actual Target:',test_target)\n",
    "print('Predicted Target:',result)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc=accuracy_score(test_target,result)\n",
    "\n",
    "print('Accuracy:',acc)\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(algorithm,'4_activity_suggestion.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
